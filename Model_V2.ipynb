{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICE_FILES = [\"data/Stocks/AlternativeEnergy_Price.csv\", \"data/Stocks/Automobile_Price.csv\", \"data/Stocks/Bank_Price.csv\",\n",
    "                        \"data/Stocks/Beverage_Price.csv\", \"data/Stocks/BioTech_Price.csv\", \"data/Stocks/Chemical_Price.csv\",\n",
    "                        \"data/Stocks/Construction_Price.csv\", \"data/Stocks/Electricity_Price.csv\", \"data/Stocks/Electronic_Price.csv\",\n",
    "                        \"data/Stocks/Finance_Price.csv\", \"data/Stocks/Fix_Price.csv\", \"data/Stocks/Food_Price.csv\", \n",
    "                        \"data/Stocks/FoodProducer_Price.csv\", \"data/Stocks/Gas_Price.csv\", \"data/Stocks/GeneralIndustrial_Price.csv\",\n",
    "                        \"data/Stocks/GeneralRetail_Price.csv\", \"data/Stocks/Hardware_Price.csv\", \"data/Stocks/Health_Price.csv\",\n",
    "                        \"data/Stocks/Household_Price.csv\", \"data/Stocks/IndustrialEngineer_Price.csv\", \"data/Stocks/IndustrialMetal_Price.csv\", \n",
    "                        \"data/Stocks/IndustrialTransport_Price.csv\", \"data/Stocks/Insurance_Price.csv\", \"data/Stocks/Leisure_Price.csv\",\n",
    "                        \"data/Stocks/Media_Price.csv\", \"data/Stocks/Mining_Price.csv\", \"data/Stocks/NonLifeInsure_Price.csv\",\n",
    "                        \"data/Stocks/OilProducer_Price.csv\", \"data/Stocks/Paper_Price.csv\", \"data/Stocks/PersonalGoods_Price.csv\",\n",
    "                        \"data/Stocks/RealEstate_Price.csv\", \"data/Stocks/Software_Price.csv\", \"data/Stocks/Support_Price.csv\",\n",
    "                        \"data/Stocks/Travel_Price.csv\", \"data/Stocks/Unclassified_Price.csv\"]\n",
    "\n",
    "VOLUME_FILES = [\"data/Stocks/AlternativeEnergy_Volume.csv\", \"data/Stocks/Automobile_Volume.csv\", \"data/Stocks/Automobile_Volume.csv\",\n",
    "                           \"data/Stocks/Beverage_Volume.csv\", \"data/Stocks/BioTech_Volume.csv\", \"data/Stocks/Chemical_Volume.csv\",\n",
    "                           \"data/Stocks/Construction_Volume.csv\", \"data/Stocks/Electricity_Volume.csv\", \"data/Stocks/Electronic_Volume.csv\",\n",
    "                           \"data/Stocks/Finance_Volume.csv\", \"data/Stocks/Fix_Volume.csv\", \"data/Stocks/Food_Volume.csv\", \n",
    "                           \"data/Stocks/FoodProducer_Volume.csv\", \"data/Stocks/Gas_Volume.csv\", \"data/Stocks/GeneralIndustrial_Volume.csv\",\n",
    "                           \"data/Stocks/GeneralRetail_Volume.csv\", \"data/Stocks/Hardware_Volume.csv\", \"data/Stocks/Health_Volume.csv\", \n",
    "                           \"data/Stocks/Household_Volume.csv\", \"data/Stocks/IndustrialEngineer_Volume.csv\", \"data/Stocks/IndustrialMetal_Volume.csv\", \n",
    "                           \"data/Stocks/IndustrialTransport_Volume.csv\", \"data/Stocks/Insurance_Volume.csv\", \"data/Stocks/Leisure_Volume.csv\",\n",
    "                           \"data/Stocks/Media_Volume.csv\", \"data/Stocks/Mining_Volume.csv\", \"data/Stocks/NonLifeInsure_Volume.csv\",\n",
    "                           \"data/Stocks/OilProducer_Volume.csv\", \"data/Stocks/Paper_Volume.csv\", \"data/Stocks/PersonalGoods_Volume.csv\",\n",
    "                           \"data/Stocks/RealEstate_Volume.csv\", \"data/Stocks/Software_Volume.csv\", \"data/Stocks/Support_Volume.csv\",\n",
    "                           \"data/Stocks/Travel_Volume.csv\", \"data/Stocks/Unclassified_Volume.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RenameHeader(col_name, col_type):\n",
    "    if col_name == \"Code\":\n",
    "        return \"Code\"\n",
    "    else:\n",
    "        if col_type == \"Price\":\n",
    "            return col_name[2:-3]\n",
    "        else:\n",
    "            return col_name[2:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePrediction(close, prediction_interval):\n",
    "    ''' Arguments: close (Pandas series containing the close price)\n",
    "        Returns: Pandas series containing true Y\n",
    "    '''\n",
    "    series = np.where(close.shift(-prediction_interval) > 1.005*close, 1, \n",
    "                                    np.where(close.shift(-prediction_interval) < 0.995*close, -1, 0))\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveNoKey(RenderList, key):\n",
    "    remove_keys = []\n",
    "    \n",
    "    for entry in RenderList:\n",
    "        if key not in entry:\n",
    "            remove_keys.append(entry[\"key\"]) # Append stock abbreviations we want to remove\n",
    "            \n",
    "    if len(remove_keys) == 0:\n",
    "        return RenderList\n",
    "    else:\n",
    "        return [x for x in RenderList if x[\"key\"] not in remove_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean(price, volume):\n",
    "    \n",
    "    \"\"\"\n",
    "    Argument: price dataframe and volume dataframe\n",
    "    Return: return the tuples of price dataframes (2014-2020) and volume dataframes (2014-2020)\n",
    "                where each one of them is filtered out missing col, missing price from prev year, missing vol from prev year,\n",
    "                        no volume traded occurs from prev year\n",
    "    Note: this function requires RenameHeader (Defined above) and pandas\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read two dataframes and filter to have files from 2014 to 2020\n",
    "    price_df = pd.read_csv(price).rename(columns = lambda x: RenameHeader(x, \"Price\"))\n",
    "    price_df['Code'] = pd.to_datetime(price_df['Code'])\n",
    "    price_df = price_df[(price_df['Code'] > '2014-01-01')]\n",
    "    \n",
    "    vol_df = pd.read_csv(volume).rename(columns = lambda x: RenameHeader(x, \"Vol\"))\n",
    "    vol_df['Code'] = pd.to_datetime(vol_df['Code'])\n",
    "    vol_df = vol_df[(vol_df['Code'] > '2014-01-01')]\n",
    "    \n",
    "    # Use only common cols in two dataframes\n",
    "    common_cols = price_df.columns.intersection(vol_df.columns).tolist()\n",
    "    price_df = price_df[common_cols]\n",
    "    vol_df = vol_df[common_cols]\n",
    "    \n",
    "    # Temporarily include SET_VOL to filter holidays\n",
    "    SET_IDX_VOL = pd.read_csv('data/SET/SET_VO.csv', parse_dates = True)\n",
    "    SET_IDX_VOL = SET_IDX_VOL.rename(columns = {'Code': 'Code', 'BNGKSET(VO)': 'Volume'})\n",
    "    SET_IDX_VOL['Code'] = pd.to_datetime(SET_IDX_VOL['Code'])\n",
    "    \n",
    "    # Filter holiday on price dataframes\n",
    "    price_df = pd.merge(price_df, SET_IDX_VOL, how = 'inner', on = 'Code')\n",
    "    price_df = price_df[price_df['Volume'].notna()]\n",
    "    price_df.drop(['Volume'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Filter holiday on price dataframes\n",
    "    vol_df = pd.merge(vol_df, SET_IDX_VOL, how = 'inner', on = 'Code')\n",
    "    vol_df = vol_df[vol_df['Volume'].notna()]\n",
    "    vol_df.drop(['Volume'], axis = 1, inplace = True)\n",
    "    \n",
    "    # loop from 2014 to 2020 to create small dataframes (useful for filtering later on)\n",
    "    price_df_s = []\n",
    "    vol_df_s = []\n",
    "    for i in range(7):\n",
    "        x = i + 2014\n",
    "        start_date = str(x) + '-01-01'\n",
    "        end_date = str(x+1) + '-01-01'\n",
    "        price_df_s.append(price_df[(price_df['Code'] > start_date) & (price_df['Code'] < end_date)])\n",
    "        vol_df_s.append(vol_df[(vol_df['Code'] > start_date) & (vol_df['Code'] < end_date)])\n",
    "        \n",
    "    # Filter the columns from 2015 to 2020 by two criterias\n",
    "    # 1) Any missing price variables from previous year\n",
    "    # 2) Any missing + zero volume from previous year\n",
    "    for i in range(6):\n",
    "        \n",
    "        price_filter_df = price_df_s[i]\n",
    "        vol_filter_df = vol_df_s[i]\n",
    "        \n",
    "        price_null = price_filter_df.columns[price_filter_df.isna().any()].tolist()\n",
    "        vol_null = vol_filter_df.columns[vol_filter_df.isna().any()].tolist()\n",
    "        # Create another copy (a bit inefficient, but it works)\n",
    "        vol_temp = vol_filter_df.drop(['Code'], axis = 1, inplace = False)\n",
    "        vol_gt_zero = vol_temp.columns[(vol_temp <= 0).any()].tolist()\n",
    "        \n",
    "        filtered_out_col = list(set().union(price_null,vol_null,vol_gt_zero))\n",
    "        \n",
    "        price_df_s[i+1].drop(filtered_out_col, axis = 1, inplace = True)\n",
    "        vol_df_s[i+1].drop(filtered_out_col, axis = 1, inplace = True)\n",
    "        \n",
    "        \n",
    "    return (price_df_s, vol_df_s)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateFeatures(price_list, vol_list):\n",
    "    \"\"\"\n",
    "    Input: price dataframes list, vol dataframes list\n",
    "    Return: list of list of dict\n",
    "    (for example, [automobile, ...] -> [2014, 2015, 2016, ...] -> {price: price_df, vol: vol_df, feature1: ...})\n",
    "    \"\"\"\n",
    "    return_list = []\n",
    "    for i in range(len(price_list)):\n",
    "        compile_list = []\n",
    "        price_df_s, vol_df_s = Clean(price_list[i], vol_list[i])\n",
    "        \n",
    "        for j in range(len(price_df_s)):\n",
    "            sub_dict = {}\n",
    "            # Initial dataframes we got from raw data\n",
    "            price_df = price_df_s[j]\n",
    "            vol_df = vol_df_s[j]\n",
    "            \n",
    "            ## Define new dataframes: this records MACD\n",
    "            trend_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            trend_df['Code'] = price_df['Code']\n",
    "            \n",
    "            ## Define new dataframes: this records momentum\n",
    "            mom3_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            mom3_df['Code'] = price_df['Code']\n",
    "            mom5_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            mom5_df['Code'] = price_df['Code']         \n",
    "            mom10_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            mom10_df['Code'] = price_df['Code']\n",
    "            mom14_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            mom14_df['Code'] = price_df['Code']\n",
    "            mom20_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            mom20_df['Code'] = price_df['Code']\n",
    "            \n",
    "            ## Define new dataframes: this records volatility (14-day STD)\n",
    "            std3_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            std3_df['Code'] = price_df['Code']      \n",
    "            std5_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            std5_df['Code'] = price_df['Code']         \n",
    "            std10_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            std10_df['Code'] = price_df['Code'] \n",
    "            std14_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            std14_df['Code'] = price_df['Code'] \n",
    "            std20_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            std20_df['Code'] = price_df['Code'] \n",
    "            \n",
    "            ## Define new dataframes: volume\n",
    "            vol_ind_df =  pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            vol_ind_df['Code'] = price_df['Code']\n",
    "            \n",
    "            ## Define prediction in each time horizon\n",
    "            y3_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            y3_df['Code'] = price_df['Code']\n",
    "            y5_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            y5_df['Code'] = price_df['Code']\n",
    "            y10_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            y10_df['Code'] = price_df['Code']\n",
    "            y14_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            y14_df['Code'] = price_df['Code']\n",
    "            y20_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            y20_df['Code'] = price_df['Code']\n",
    "            yn1_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            yn1_df['Code'] = price_df['Code']\n",
    "            \n",
    "            \n",
    "            for col in list(price_df.columns):\n",
    "                if col != 'Code':\n",
    "                    \n",
    "                    # Record MACD\n",
    "                    trend_df[col] = price_df.loc[:, col].ewm(span=12, adjust=False).mean() - price_df.loc[:, col].ewm(span=26, adjust=False).mean() \n",
    "                    \n",
    "                    # Record pct_change as momentum\n",
    "                    mom3_df[col] = price_df.loc[:, col].pct_change(periods = 3)\n",
    "                    mom5_df[col] = price_df.loc[:, col].pct_change(periods = 5)\n",
    "                    mom10_df[col] = price_df.loc[:, col].pct_change(periods = 10)\n",
    "                    mom14_df[col] = price_df.loc[:, col].pct_change(periods = 14)\n",
    "                    mom20_df[col] = price_df.loc[:, col].pct_change(periods = 20)\n",
    "                    \n",
    "                    # Record rolling std\n",
    "                    std3_df[col] = price_df.loc[:, col].rolling(3).std()\n",
    "                    std5_df[col] = price_df.loc[:, col].rolling(5).std()\n",
    "                    std10_df[col] = price_df.loc[:, col].rolling(10).std()\n",
    "                    std14_df[col] = price_df.loc[:, col].rolling(14).std()\n",
    "                    std20_df[col] = price_df.loc[:, col].rolling(20).std()\n",
    "                    \n",
    "                    # Record volume indicator\n",
    "                    vol_ind_df[col] = (vol_df.loc[:, col].rolling(window=2).mean() - vol_df.loc[:, col].rolling(window=14).mean()).apply(lambda x: 1 if x > 0 else 0)\n",
    "                    \n",
    "                    # Record rolling prediction\n",
    "                    y3_df[col] = generatePrediction(price_df.loc[:, col], 3)\n",
    "                    y5_df[col] = generatePrediction(price_df.loc[:, col], 5)\n",
    "                    y10_df[col] = generatePrediction(price_df.loc[:, col], 10)\n",
    "                    y14_df[col] = generatePrediction(price_df.loc[:, col], 14)\n",
    "                    y20_df[col] = generatePrediction(price_df.loc[:, col], 20)\n",
    "                    yn1_df[col] = generatePrediction(price_df.loc[:, col], -1)\n",
    "            \n",
    "            sub_dict['price'] = price_df\n",
    "            sub_dict['vol'] = vol_df\n",
    "            \n",
    "            sub_dict['trend'] = trend_df\n",
    "            \n",
    "            sub_dict['vol_sig'] =  vol_ind_df\n",
    "            \n",
    "            sub_dict['mom3'] = mom3_df\n",
    "            sub_dict['mom5'] = mom5_df\n",
    "            sub_dict['mom10'] = mom10_df\n",
    "            sub_dict['mom14'] = mom14_df\n",
    "            sub_dict['mom20'] = mom20_df\n",
    "                        \n",
    "            sub_dict['std3'] = std3_df\n",
    "            sub_dict['std5'] = std5_df     \n",
    "            sub_dict['std10'] = std10_df\n",
    "            sub_dict['std14'] = std14_df     \n",
    "            sub_dict['std20'] = std20_df\n",
    "            \n",
    "            sub_dict['y3'] = y3_df\n",
    "            sub_dict['y5'] = y5_df\n",
    "            sub_dict['y10'] = y10_df\n",
    "            sub_dict['y14'] = y14_df\n",
    "            sub_dict['y20'] = y20_df\n",
    "            sub_dict['yn1'] = yn1_df\n",
    "            \n",
    "            compile_list.append(sub_dict)\n",
    "            \n",
    "        return_list.append(compile_list)\n",
    "        \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rearrange(sector_list):\n",
    "    \"\"\"\n",
    "    Input: sector_list (return list from GenerateFeatures function above)\n",
    "    Return: list of list of dict as follows\n",
    "        [2014, 2015, 2016, ...] -> {key: PTT, data: dataframes}\n",
    "        (similar how we usually render in React)\n",
    "    \"\"\"\n",
    "    # Each sublist is for each year\n",
    "    return_list = [[], [], [], [], [], [], []]\n",
    "    \n",
    "    # i runs from 0 to # of sectors - 1\n",
    "    for i in range(len(sector_list)):\n",
    "        sector_stocks = sector_list[i]\n",
    "        # j runs from 0 to 6 (0 -> 2014, 6 -> 2020)\n",
    "        for j in range(7):\n",
    "            sector_year_dict = sector_stocks[j]\n",
    "            col_names = sector_year_dict['price'].columns.tolist()\n",
    "            # k runs for each column except \"Code\"\n",
    "            for k in range(1, len(col_names)):\n",
    "                stock_name = col_names[k]\n",
    "                # Step 1: create blank dataframes\n",
    "                COLS = ['Code', 'vol', 'price', 'trend', 'mom3', 'mom5', 'mom10', 'mom14', 'mom20', 'std3', 'std5', 'std10', 'std14', 'std20', 'vol_sig', 'y3', 'y5', 'y10', 'y14', 'y20', 'yn1']\n",
    "                new_data = pd.DataFrame(index=sector_year_dict['price'].index, columns= COLS)\n",
    "                new_data['Code'] = sector_year_dict['price']['Code']\n",
    "                \n",
    "                # Step 2: Retrieve data from the key and insert it into new_data\n",
    "                \n",
    "                new_data['vol'] = sector_year_dict['vol'].loc[:, stock_name]\n",
    "                new_data['price'] = sector_year_dict['price'].loc[:, stock_name]\n",
    "                new_data['trend'] = sector_year_dict['trend'].loc[:, stock_name]\n",
    "                new_data['mom3'] = sector_year_dict['mom3'].loc[:, stock_name]\n",
    "                new_data['mom5'] = sector_year_dict['mom5'].loc[:, stock_name]\n",
    "                new_data['mom10'] = sector_year_dict['mom10'].loc[:, stock_name]\n",
    "                new_data['mom14'] = sector_year_dict['mom14'].loc[:, stock_name]\n",
    "                new_data['mom20'] = sector_year_dict['mom20'].loc[:, stock_name]\n",
    "                new_data['std3'] = sector_year_dict['std3'].loc[:, stock_name]\n",
    "                new_data['std5'] = sector_year_dict['std5'].loc[:, stock_name]\n",
    "                new_data['std10'] = sector_year_dict['std10'].loc[:, stock_name]\n",
    "                new_data['std14'] = sector_year_dict['std14'].loc[:, stock_name]\n",
    "                new_data['std20'] = sector_year_dict['std20'].loc[:, stock_name]\n",
    "                new_data['vol_sig'] = sector_year_dict['vol_sig'].loc[:, stock_name]\n",
    "                new_data['y3'] = sector_year_dict['y3'].loc[:, stock_name]\n",
    "                new_data['y5'] = sector_year_dict['y5'].loc[:, stock_name]\n",
    "                new_data['y10'] = sector_year_dict['y10'].loc[:, stock_name]\n",
    "                new_data['y14'] = sector_year_dict['y14'].loc[:, stock_name]\n",
    "                new_data['y20'] = sector_year_dict['y20'].loc[:, stock_name]\n",
    "                new_data['yn1'] = sector_year_dict['yn1'].loc[:, stock_name]\n",
    "                \n",
    "                # Step 3: Drop rows with at least one missing value\n",
    "                new_data.dropna(axis = 0, how = 'any', inplace = True)\n",
    "                \n",
    "                # Step 4: Insert the new_dataframe into appropriate place (notice we use dict for convenience later)\n",
    "                new_dict = {'key': stock_name, 'data': new_data}\n",
    "                return_list[j].append(new_dict)\n",
    "                \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetVolumeTraded(RenderList):\n",
    "    \"\"\"\n",
    "    input: RenderList, using the same data structure corresponding to Rearrange function (defined above)\n",
    "    Process: Add key of volume_traded in each stock-year (calculated from last year)\n",
    "    Return: nothing\n",
    "    \"\"\"\n",
    "    # For each year from 2015 to 2020\n",
    "    for i in range(1, 7):\n",
    "        \n",
    "        # For each stock that we want to add the new key: volume traded\n",
    "        for stock in RenderList[i]:\n",
    "            stock_name = stock['key']\n",
    "            \n",
    "            prev_data = RenderList[i-1]\n",
    "            \n",
    "            # This is inefficient, but it's okay, because otherwise, we need to change the whole data structure\n",
    "            for prev_stock in prev_data:\n",
    "                if prev_stock['key'] == stock_name:\n",
    "                    # Calculate the latest volume in last year\n",
    "                    stock['volume_traded'] = prev_stock['data'].loc[:, 'vol'].iloc[-1]\n",
    "                    # Calculate # of ups in dfs as proportions\n",
    "                    stock['up3'] = (prev_stock['data'].loc[:, 'y3'] == 1).mean()\n",
    "                    stock['up5'] = (prev_stock['data'].loc[:, 'y5'] == 1).mean()\n",
    "                    stock['up10'] = (prev_stock['data'].loc[:, 'y10'] == 1).mean()\n",
    "                    stock['up14'] = (prev_stock['data'].loc[:, 'y14'] == 1).mean()\n",
    "                    stock['up20'] = (prev_stock['data'].loc[:, 'y20'] == 1).mean()\n",
    "                    # Calculate # of downs in dfs as proportions\n",
    "                    stock['down3'] = (prev_stock['data'].loc[:, 'y3'] == -1).mean()\n",
    "                    stock['down5'] = (prev_stock['data'].loc[:, 'y5'] == -1).mean()\n",
    "                    stock['down10'] = (prev_stock['data'].loc[:, 'y10'] == -1).mean()\n",
    "                    stock['down14'] = (prev_stock['data'].loc[:, 'y14'] == -1).mean()\n",
    "                    stock['down20'] = (prev_stock['data'].loc[:, 'y20'] == -1).mean()\n",
    "                    # Calculate average MACD of that stock\n",
    "                    stock['MACD'] = prev_stock['data'].loc[:, 'trend'].mean()\n",
    "                    # Calculate average mom of that stock\n",
    "                    stock['mom3'] = prev_stock['data'].loc[:, 'mom3'].mean()\n",
    "                    stock['mom5'] = prev_stock['data'].loc[:, 'mom5'].mean()\n",
    "                    stock['mom10'] = prev_stock['data'].loc[:, 'mom10'].mean()\n",
    "                    stock['mom14'] = prev_stock['data'].loc[:, 'mom14'].mean()\n",
    "                    stock['mom20'] = prev_stock['data'].loc[:, 'mom20'].mean()                    \n",
    "                    # Calculate average STD of that stock\n",
    "                    stock['std3'] = prev_stock['data'].loc[:, 'std3'].mean()\n",
    "                    stock['std5'] = prev_stock['data'].loc[:, 'std5'].mean()\n",
    "                    stock['std10'] = prev_stock['data'].loc[:, 'std10'].mean()\n",
    "                    stock['std14'] = prev_stock['data'].loc[:, 'std14'].mean()\n",
    "                    stock['std20'] = prev_stock['data'].loc[:, 'std20'].mean()\n",
    "                    # Calculate proportion of strong volume signal of that stock\n",
    "                    stock['vol_sig'] = prev_stock['data'].loc[:, 'vol_sig'].mean()\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTable(RenderList, columns):\n",
    "    \"\"\"\n",
    "    Input: RenderList, using the same data structure corresponding to Rearrange function and has the key volume_traded\n",
    "    This will output the result of average coefficient across five years into csv file\n",
    "    Return: nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(1, 7):\n",
    "        \n",
    "        YEAR = str(i+2014)\n",
    "        \n",
    "        # Returned dataframe\n",
    "        return_df = pd.DataFrame(index=range(10) , columns= columns)\n",
    "        return_df = return_df.fillna(0)\n",
    "        \n",
    "        ## For debug purpose\n",
    "        print('We are at year ' + str(i))\n",
    "        \n",
    "        # Sort by volume traded and split into ten sub-lists\n",
    "        stock_list = RemoveNoKey(RenderList[i], 'volume_traded')\n",
    "        stock_list = sorted(stock_list, key = lambda x: x['volume_traded'])\n",
    "        ten_splits = np.array_split(stock_list, 10)\n",
    "        \n",
    "        for j in range(10):\n",
    "            ## For debug purpose\n",
    "            print('---> We are at decile of ' + str(j) + ' consisting of '+ str(len(ten_splits[j])) + ' firms!')\n",
    "            \n",
    "            X = [0 for x in range(len(columns))]\n",
    "            \n",
    "            for Render in ten_splits[j]:                \n",
    "                for col_idx in range(len(columns)):\n",
    "                    X[col_idx] += Render[columns[col_idx]]\n",
    "                    \n",
    "            for col_idx in range(len(columns)):\n",
    "                X[col_idx] = X[col_idx]/len(ten_splits[j])\n",
    "                return_df.iloc[j, col_idx] = X[col_idx]\n",
    "        \n",
    "        return_df.to_csv('Model_V2_' + YEAR + '.csv')          \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "cleaned_dfs = GenerateFeatures(PRICE_FILES, VOLUME_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "RenderList = Rearrange(cleaned_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetVolumeTraded(RenderList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(RenderList[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at year 1\n",
      "---> We are at decile of 0 consisting of 27 firms!\n",
      "---> We are at decile of 1 consisting of 27 firms!\n",
      "---> We are at decile of 2 consisting of 27 firms!\n",
      "---> We are at decile of 3 consisting of 27 firms!\n",
      "---> We are at decile of 4 consisting of 27 firms!\n",
      "---> We are at decile of 5 consisting of 26 firms!\n",
      "---> We are at decile of 6 consisting of 26 firms!\n",
      "---> We are at decile of 7 consisting of 26 firms!\n",
      "---> We are at decile of 8 consisting of 26 firms!\n",
      "---> We are at decile of 9 consisting of 26 firms!\n",
      "We are at year 2\n",
      "---> We are at decile of 0 consisting of 25 firms!\n",
      "---> We are at decile of 1 consisting of 25 firms!\n",
      "---> We are at decile of 2 consisting of 25 firms!\n",
      "---> We are at decile of 3 consisting of 25 firms!\n",
      "---> We are at decile of 4 consisting of 25 firms!\n",
      "---> We are at decile of 5 consisting of 25 firms!\n",
      "---> We are at decile of 6 consisting of 24 firms!\n",
      "---> We are at decile of 7 consisting of 24 firms!\n",
      "---> We are at decile of 8 consisting of 24 firms!\n",
      "---> We are at decile of 9 consisting of 24 firms!\n",
      "We are at year 3\n",
      "---> We are at decile of 0 consisting of 34 firms!\n",
      "---> We are at decile of 1 consisting of 34 firms!\n",
      "---> We are at decile of 2 consisting of 33 firms!\n",
      "---> We are at decile of 3 consisting of 33 firms!\n",
      "---> We are at decile of 4 consisting of 33 firms!\n",
      "---> We are at decile of 5 consisting of 33 firms!\n",
      "---> We are at decile of 6 consisting of 33 firms!\n",
      "---> We are at decile of 7 consisting of 33 firms!\n",
      "---> We are at decile of 8 consisting of 33 firms!\n",
      "---> We are at decile of 9 consisting of 33 firms!\n",
      "We are at year 4\n",
      "---> We are at decile of 0 consisting of 33 firms!\n",
      "---> We are at decile of 1 consisting of 33 firms!\n",
      "---> We are at decile of 2 consisting of 33 firms!\n",
      "---> We are at decile of 3 consisting of 33 firms!\n",
      "---> We are at decile of 4 consisting of 33 firms!\n",
      "---> We are at decile of 5 consisting of 33 firms!\n",
      "---> We are at decile of 6 consisting of 32 firms!\n",
      "---> We are at decile of 7 consisting of 32 firms!\n",
      "---> We are at decile of 8 consisting of 32 firms!\n",
      "---> We are at decile of 9 consisting of 32 firms!\n",
      "We are at year 5\n",
      "---> We are at decile of 0 consisting of 38 firms!\n",
      "---> We are at decile of 1 consisting of 38 firms!\n",
      "---> We are at decile of 2 consisting of 38 firms!\n",
      "---> We are at decile of 3 consisting of 38 firms!\n",
      "---> We are at decile of 4 consisting of 38 firms!\n",
      "---> We are at decile of 5 consisting of 38 firms!\n",
      "---> We are at decile of 6 consisting of 38 firms!\n",
      "---> We are at decile of 7 consisting of 38 firms!\n",
      "---> We are at decile of 8 consisting of 38 firms!\n",
      "---> We are at decile of 9 consisting of 37 firms!\n",
      "We are at year 6\n",
      "---> We are at decile of 0 consisting of 35 firms!\n",
      "---> We are at decile of 1 consisting of 34 firms!\n",
      "---> We are at decile of 2 consisting of 34 firms!\n",
      "---> We are at decile of 3 consisting of 34 firms!\n",
      "---> We are at decile of 4 consisting of 34 firms!\n",
      "---> We are at decile of 5 consisting of 34 firms!\n",
      "---> We are at decile of 6 consisting of 34 firms!\n",
      "---> We are at decile of 7 consisting of 34 firms!\n",
      "---> We are at decile of 8 consisting of 34 firms!\n",
      "---> We are at decile of 9 consisting of 34 firms!\n"
     ]
    }
   ],
   "source": [
    "COLS = ['up3', 'up5', 'up10', 'up14', 'up20', 'down3', 'down5', 'down10', 'down14', 'down20', 'MACD', 'mom3', 'mom5', 'mom10', 'mom14', 'mom20', 'std3', 'std5', 'std10', 'std14', 'std20', 'vol_sig']\n",
    "GenerateTable(RenderList, COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
