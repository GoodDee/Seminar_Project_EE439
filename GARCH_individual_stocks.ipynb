{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICE_FILES = [\"data/Stocks/AlternativeEnergy_Price.csv\", \"data/Stocks/Automobile_Price.csv\", \"data/Stocks/Bank_Price.csv\",\n",
    "                        \"data/Stocks/Beverage_Price.csv\", \"data/Stocks/BioTech_Price.csv\", \"data/Stocks/Chemical_Price.csv\",\n",
    "                        \"data/Stocks/Construction_Price.csv\", \"data/Stocks/Electricity_Price.csv\", \"data/Stocks/Electronic_Price.csv\",\n",
    "                        \"data/Stocks/Finance_Price.csv\", \"data/Stocks/Fix_Price.csv\", \"data/Stocks/Food_Price.csv\", \n",
    "                        \"data/Stocks/FoodProducer_Price.csv\", \"data/Stocks/Gas_Price.csv\", \"data/Stocks/GeneralIndustrial_Price.csv\",\n",
    "                        \"data/Stocks/GeneralRetail_Price.csv\", \"data/Stocks/Hardware_Price.csv\", \"data/Stocks/Health_Price.csv\",\n",
    "                        \"data/Stocks/Household_Price.csv\", \"data/Stocks/IndustrialEngineer_Price.csv\", \"data/Stocks/IndustrialMetal_Price.csv\", \n",
    "                        \"data/Stocks/IndustrialTransport_Price.csv\", \"data/Stocks/Insurance_Price.csv\", \"data/Stocks/Leisure_Price.csv\",\n",
    "                        \"data/Stocks/Media_Price.csv\", \"data/Stocks/Mining_Price.csv\", \"data/Stocks/NonLifeInsure_Price.csv\",\n",
    "                        \"data/Stocks/OilProducer_Price.csv\", \"data/Stocks/Paper_Price.csv\", \"data/Stocks/PersonalGoods_Price.csv\",\n",
    "                        \"data/Stocks/RealEstate_Price.csv\", \"data/Stocks/Software_Price.csv\", \"data/Stocks/Support_Price.csv\",\n",
    "                        \"data/Stocks/Travel_Price.csv\", \"data/Stocks/Unclassified_Price.csv\"]\n",
    "\n",
    "VOLUME_FILES = [\"data/Stocks/AlternativeEnergy_Volume.csv\", \"data/Stocks/Automobile_Volume.csv\", \"data/Stocks/Automobile_Volume.csv\",\n",
    "                           \"data/Stocks/Beverage_Volume.csv\", \"data/Stocks/BioTech_Volume.csv\", \"data/Stocks/Chemical_Volume.csv\",\n",
    "                           \"data/Stocks/Construction_Volume.csv\", \"data/Stocks/Electricity_Volume.csv\", \"data/Stocks/Electronic_Volume.csv\",\n",
    "                           \"data/Stocks/Finance_Volume.csv\", \"data/Stocks/Fix_Volume.csv\", \"data/Stocks/Food_Volume.csv\", \n",
    "                           \"data/Stocks/FoodProducer_Volume.csv\", \"data/Stocks/Gas_Volume.csv\", \"data/Stocks/GeneralIndustrial_Volume.csv\",\n",
    "                           \"data/Stocks/GeneralRetail_Volume.csv\", \"data/Stocks/Hardware_Volume.csv\", \"data/Stocks/Health_Volume.csv\", \n",
    "                           \"data/Stocks/Household_Volume.csv\", \"data/Stocks/IndustrialEngineer_Volume.csv\", \"data/Stocks/IndustrialMetal_Volume.csv\", \n",
    "                           \"data/Stocks/IndustrialTransport_Volume.csv\", \"data/Stocks/Insurance_Volume.csv\", \"data/Stocks/Leisure_Volume.csv\",\n",
    "                           \"data/Stocks/Media_Volume.csv\", \"data/Stocks/Mining_Volume.csv\", \"data/Stocks/NonLifeInsure_Volume.csv\",\n",
    "                           \"data/Stocks/OilProducer_Volume.csv\", \"data/Stocks/Paper_Volume.csv\", \"data/Stocks/PersonalGoods_Volume.csv\",\n",
    "                           \"data/Stocks/RealEstate_Volume.csv\", \"data/Stocks/Software_Volume.csv\", \"data/Stocks/Support_Volume.csv\",\n",
    "                           \"data/Stocks/Travel_Volume.csv\", \"data/Stocks/Unclassified_Volume.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RenameHeader(col_name, col_type):\n",
    "    if col_name == \"Code\":\n",
    "        return \"Code\"\n",
    "    else:\n",
    "        if col_type == \"Price\":\n",
    "            return col_name[2:-3]\n",
    "        else:\n",
    "            return col_name[2:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean(price, volume):\n",
    "    \n",
    "    \"\"\"\n",
    "    Argument: price dataframe and volume dataframe\n",
    "    Return: return the tuples of price dataframes (2014-2019) and volume dataframes (2014-2019)\n",
    "                where each one of them is filtered out missing col, missing price from prev year, missing vol from prev year,\n",
    "                        no volume traded occurs from prev year\n",
    "    Note: this function requires RenameHeader (Defined above) and pandas\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read two dataframes and filter to have files from 2014 to 2019\n",
    "    price_df = pd.read_csv(price).rename(columns = lambda x: RenameHeader(x, \"Price\"))\n",
    "    price_df['Code'] = pd.to_datetime(price_df['Code'])\n",
    "    price_df = price_df[(price_df['Code'] > '2014-01-01') & (price_df['Code'] < '2020-01-01')]\n",
    "    \n",
    "    vol_df = pd.read_csv(volume).rename(columns = lambda x: RenameHeader(x, \"Vol\"))\n",
    "    vol_df['Code'] = pd.to_datetime(vol_df['Code'])\n",
    "    vol_df = vol_df[(vol_df['Code'] > '2014-01-01') & (vol_df['Code'] < '2020-01-01')]\n",
    "    \n",
    "    # Use only common cols in two dataframes\n",
    "    common_cols = price_df.columns.intersection(vol_df.columns).tolist()\n",
    "    price_df = price_df[common_cols]\n",
    "    vol_df = vol_df[common_cols]\n",
    "    \n",
    "    # Temporarily include SET_VOL to filter holidays\n",
    "    SET_IDX_VOL = pd.read_csv('data/SET/SET_VO.csv', parse_dates = True)\n",
    "    SET_IDX_VOL = SET_IDX_VOL.rename(columns = {'Code': 'Code', 'BNGKSET(VO)': 'Volume'})\n",
    "    SET_IDX_VOL['Code'] = pd.to_datetime(SET_IDX_VOL['Code'])\n",
    "    \n",
    "    # Filter holiday on price dataframes\n",
    "    price_df = pd.merge(price_df, SET_IDX_VOL, how = 'inner', on = 'Code')\n",
    "    price_df = price_df[price_df['Volume'].notna()]\n",
    "    price_df.drop(['Volume'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Filter holiday on price dataframes\n",
    "    vol_df = pd.merge(vol_df, SET_IDX_VOL, how = 'inner', on = 'Code')\n",
    "    vol_df = vol_df[vol_df['Volume'].notna()]\n",
    "    vol_df.drop(['Volume'], axis = 1, inplace = True)\n",
    "    \n",
    "    # loop from 2014 to 2019 to create small dataframes (useful for filtering later on)\n",
    "    price_df_s = []\n",
    "    vol_df_s = []\n",
    "    for i in range(6):\n",
    "        x = i + 2014\n",
    "        start_date = str(x) + '-01-01'\n",
    "        end_date = str(x+1) + '-01-01'\n",
    "        price_df_s.append(price_df[(price_df['Code'] > start_date) & (price_df['Code'] < end_date)])\n",
    "        vol_df_s.append(vol_df[(vol_df['Code'] > start_date) & (vol_df['Code'] < end_date)])\n",
    "        \n",
    "    # Filter the columns from 2015 to 2019 by two criterias\n",
    "    # 1) Any missing price variables from previous year\n",
    "    # 2) Any missing + zero volume from previous year\n",
    "    for i in range(5):\n",
    "        \n",
    "        price_filter_df = price_df_s[i]\n",
    "        vol_filter_df = vol_df_s[i]\n",
    "        \n",
    "        price_null = price_filter_df.columns[price_filter_df.isna().any()].tolist()\n",
    "        vol_null = vol_filter_df.columns[vol_filter_df.isna().any()].tolist()\n",
    "        # Create another copy (a bit inefficient, but it works)\n",
    "        vol_temp = vol_filter_df.drop(['Code'], axis = 1, inplace = False)\n",
    "        vol_gt_zero = vol_temp.columns[(vol_temp <= 0).any()].tolist()\n",
    "        \n",
    "        filtered_out_col = list(set().union(price_null,vol_null,vol_gt_zero))\n",
    "        \n",
    "        price_df_s[i+1].drop(filtered_out_col, axis = 1, inplace = True)\n",
    "        vol_df_s[i+1].drop(filtered_out_col, axis = 1, inplace = True)\n",
    "        \n",
    "        \n",
    "    return (price_df_s, vol_df_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateFeatures(price_list, vol_list):\n",
    "    \"\"\"\n",
    "    Input: price dataframes list, vol dataframes list\n",
    "    Return: list of list of dict\n",
    "    (for example, [automobile, ...] -> [2014, 2015, 2016, ...] -> {price: price_df, vol: vol_df, feature1: ...})\n",
    "    \"\"\"\n",
    "    return_list = []\n",
    "    for i in range(len(price_list)):\n",
    "        compile_list = []\n",
    "        price_df_s, vol_df_s = Clean(price_list[i], vol_list[i])\n",
    "        \n",
    "        for j in range(len(price_df_s)):\n",
    "            sub_dict = {}\n",
    "            price_df = price_df_s[j]\n",
    "            vol_df = vol_df_s[j]\n",
    "            \n",
    "            ## Define new dataframes: return dataframe\n",
    "            return3_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            return3_df['Code'] = price_df['Code']\n",
    "            \n",
    "            return5_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            return5_df['Code'] = price_df['Code']    \n",
    "            \n",
    "            return10_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            return10_df['Code'] = price_df['Code']\n",
    "            \n",
    "            return14_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            return14_df['Code'] = price_df['Code']\n",
    "            \n",
    "            return20_df = pd.DataFrame(index=price_df.index, columns=price_df.columns)\n",
    "            return20_df['Code'] = price_df['Code']\n",
    "            \n",
    "            for col in list(price_df.columns):\n",
    "                if col != 'Code':\n",
    "                    return3_df[col] = 100*price_df.loc[:, col].pct_change(periods = 3)\n",
    "                    return5_df[col] = 100*price_df.loc[:, col].pct_change(periods = 5)\n",
    "                    return10_df[col] = 100*price_df.loc[:, col].pct_change(periods = 10)\n",
    "                    return14_df[col] = 100*price_df.loc[:, col].pct_change(periods = 14)\n",
    "                    return20_df[col] = 100*price_df.loc[:, col].pct_change(periods = 20)\n",
    "                    \n",
    "            \n",
    "            sub_dict['price'] = price_df\n",
    "            sub_dict['vol'] = vol_df\n",
    "            sub_dict['ret_3'] = return3_df\n",
    "            sub_dict['ret_5'] = return5_df     \n",
    "            sub_dict['ret_10'] = return10_df\n",
    "            sub_dict['ret_14'] = return14_df\n",
    "            sub_dict['ret_20'] = return20_df\n",
    "\n",
    "            compile_list.append(sub_dict)\n",
    "            \n",
    "        return_list.append(compile_list)\n",
    "        \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rearrange(sector_list):\n",
    "    \"\"\"\n",
    "    Input: sector_list (return list from GenerateFeatures function above)\n",
    "    Return: list of list of dict as follows\n",
    "        [2014, 2015, 2016, ...] -> {key: PTT, data: dataframes}\n",
    "        (similar how we usually render in React)\n",
    "    \"\"\"\n",
    "    # Each sublist is for each year\n",
    "    return_list = [[], [], [], [], [], []]\n",
    "    \n",
    "    # i runs from 0 to # of sectors - 1\n",
    "    for i in range(len(sector_list)):\n",
    "        sector_stocks = sector_list[i]\n",
    "        # j runs from 0 to 5 (0 -> 2014, 5 -> 2019)\n",
    "        for j in range(6):\n",
    "            sector_year_dict = sector_stocks[j]\n",
    "            col_names = sector_year_dict['price'].columns.tolist()\n",
    "            # k runs for each column except \"Code\"\n",
    "            for k in range(1, len(col_names)):\n",
    "                stock_name = col_names[k]\n",
    "                # Step 1: create blank dataframes\n",
    "                new_data = pd.DataFrame(index=sector_year_dict['price'].index, columns= ['Code', 'vol', 'price', 'ret_3', 'ret_5', 'ret_10', 'ret_14', 'ret_20'])\n",
    "                new_data['Code'] = sector_year_dict['price']['Code']\n",
    "                # Step 2: Retrieve data from the key and insert it into new_data\n",
    "                new_data['vol'] = sector_year_dict['vol'].loc[:, stock_name]\n",
    "                new_data['price'] = sector_year_dict['price'].loc[:, stock_name]\n",
    "                new_data['ret_3'] = sector_year_dict['ret_3'].loc[:, stock_name]\n",
    "                new_data['ret_5'] = sector_year_dict['ret_5'].loc[:, stock_name]\n",
    "                new_data['ret_10'] = sector_year_dict['ret_10'].loc[:, stock_name]\n",
    "                new_data['ret_14'] = sector_year_dict['ret_14'].loc[:, stock_name]\n",
    "                new_data['ret_20'] = sector_year_dict['ret_20'].loc[:, stock_name]\n",
    "                \n",
    "                # Step 3: Drop rows with at least one missing value\n",
    "                new_data.dropna(axis = 0, how = 'any', inplace = True)\n",
    "                # Step 4: Insert the new_dataframe into appropriate place (notice we use dict for convenience later)\n",
    "                new_dict = {'key': stock_name, 'data': new_data}\n",
    "                return_list[j].append(new_dict)\n",
    "                \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetVolumeTraded(RenderList):\n",
    "    \"\"\"\n",
    "    input: RenderList, using the same data structure corresponding to Rearrange function (defined above)\n",
    "    Process: Add key of volume_traded in each stock-year (calculated from last year)\n",
    "    Return: nothing\n",
    "    \"\"\"\n",
    "    # For each year from 2015 to 2019\n",
    "    for i in range(1, 6):\n",
    "        \n",
    "        # For each stock that we want to add the new key: volume traded\n",
    "        for stock in RenderList[i]:\n",
    "            stock_name = stock['key']\n",
    "            \n",
    "            prev_data = RenderList[i-1]\n",
    "            \n",
    "            # This is inefficient, but it's okay, because otherwise, we need to change the whole data structure\n",
    "            for prev_stock in prev_data:\n",
    "                if prev_stock['key'] == stock_name:\n",
    "                    # Calculate the latest volume in last year\n",
    "                    stock['volume_traded'] = prev_stock['data'].loc[:, 'vol'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveNoKey(RenderList, key):\n",
    "    remove_keys = []\n",
    "    \n",
    "    for entry in RenderList:\n",
    "        if key not in entry:\n",
    "            remove_keys.append(entry[\"key\"]) # Append stock abbreviations we want to remove\n",
    "            \n",
    "    if len(remove_keys) == 0:\n",
    "        return RenderList\n",
    "    else:\n",
    "        return [x for x in RenderList if x[\"key\"] not in remove_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "\n",
    "def GenerateTable_GARCH(RenderList):\n",
    "    \"\"\"\n",
    "    Input: RenderList, using the same data structure corresponding to Rearrange function and has the key volume_traded\n",
    "    This will output the result of average coefficient across five years into csv file\n",
    "    Return: nothing\n",
    "    \"\"\"\n",
    "    # This is the return dataframe with three columns corresponding to each coefficient\n",
    "    return3_df = pd.DataFrame(index=range(10) , columns= ['alpha', 'gamma', 'beta'])\n",
    "    return3_df = return3_df.fillna(0)\n",
    "    \n",
    "    return5_df = pd.DataFrame(index=range(10) , columns= ['alpha', 'gamma', 'beta'])\n",
    "    return5_df = return5_df.fillna(0)\n",
    "    \n",
    "    return10_df = pd.DataFrame(index=range(10) , columns= ['alpha', 'gamma', 'beta'])\n",
    "    return10_df = return10_df.fillna(0)\n",
    "    \n",
    "    return14_df = pd.DataFrame(index=range(10) , columns= ['alpha', 'gamma', 'beta'])\n",
    "    return14_df = return14_df.fillna(0)\n",
    "    \n",
    "    return20_df = pd.DataFrame(index=range(10) , columns= ['alpha', 'gamma', 'beta'])\n",
    "    return20_df = return20_df.fillna(0)\n",
    "    \n",
    "    for i in range(1, 6):\n",
    "        ## For debug purpose\n",
    "        print('We are at year ' + str(i))\n",
    "        # Sort by volume traded and split into ten sub-lists\n",
    "        stock_list = RemoveNoKey(RenderList[i], 'volume_traded')\n",
    "        stock_list = sorted(stock_list, key = lambda x: x['volume_traded'])\n",
    "        ten_splits = np.array_split(stock_list, 10)\n",
    "        for j in range(10):\n",
    "            ## For debug purpose\n",
    "            print('---> We are at decile of ' + str(j) + ' consisting of '+ str(len(ten_splits[j])) + ' firms!')\n",
    "            \n",
    "            # Accumulator\n",
    "            ret3_alpha, ret3_gamma, ret3_beta = 0, 0, 0\n",
    "            ret5_alpha, ret5_gamma, ret5_beta = 0, 0, 0\n",
    "            ret10_alpha, ret10_gamma, ret10_beta = 0, 0, 0\n",
    "            ret14_alpha, ret14_gamma, ret14_beta = 0, 0, 0\n",
    "            ret20_alpha, ret20_gamma, ret20_beta = 0, 0, 0\n",
    "            \n",
    "            for Render in ten_splits[j]:\n",
    "                combined_df = Render['data']\n",
    "                \n",
    "                # Run first model: Ret on 3\n",
    "                am_3 = arch_model(combined_df['ret_3'], p=1, o=1, q=1)\n",
    "                res_3 = am_3.fit(update_freq=5, disp='off')\n",
    "                alpha_3, gamma_3, beta_3 = res_3.params['alpha[1]'], res_3.params['gamma[1]'], res_3.params['beta[1]']\n",
    "                ret3_alpha += alpha_3\n",
    "                ret3_gamma += gamma_3\n",
    "                ret3_beta += beta_3\n",
    "                \n",
    "                am_5 = arch_model(combined_df['ret_5'], p=1, o=1, q=1)\n",
    "                res_5 = am_5.fit(update_freq=5, disp='off')\n",
    "                alpha_5, gamma_5, beta_5 = res_5.params['alpha[1]'], res_5.params['gamma[1]'], res_5.params['beta[1]']\n",
    "                ret5_alpha += alpha_5\n",
    "                ret5_gamma += gamma_5\n",
    "                ret5_beta += beta_5\n",
    "                \n",
    "                am_10 = arch_model(combined_df['ret_10'], p=1, o=1, q=1)\n",
    "                res_10 = am_10.fit(update_freq=5, disp='off')   \n",
    "                alpha_10, gamma_10, beta_10 = res_10.params['alpha[1]'], res_10.params['gamma[1]'], res_10.params['beta[1]']\n",
    "                ret10_alpha += alpha_10\n",
    "                ret10_gamma += gamma_10\n",
    "                ret10_beta += beta_10\n",
    "                \n",
    "                am_14 = arch_model(combined_df['ret_14'], p=1, o=1, q=1)\n",
    "                res_14 = am_5.fit(update_freq=5, disp='off')   \n",
    "                alpha_14, gamma_14, beta_14 = res_14.params['alpha[1]'], res_14.params['gamma[1]'], res_14.params['beta[1]']\n",
    "                ret14_alpha += alpha_14\n",
    "                ret14_gamma += gamma_14\n",
    "                ret14_beta += beta_14\n",
    "                \n",
    "                am_20 = arch_model(combined_df['ret_20'], p=1, o=1, q=1)\n",
    "                res_20 = am_20.fit(update_freq=5, disp='off')   \n",
    "                alpha_20, gamma_20, beta_20 = res_20.params['alpha[1]'], res_20.params['gamma[1]'], res_20.params['beta[1]']\n",
    "                ret20_alpha += alpha_20\n",
    "                ret20_gamma += gamma_20\n",
    "                ret20_beta += beta_20\n",
    "                \n",
    "            return3_df.loc[j, 'alpha'] += (ret3_alpha/len(ten_splits[j]))\n",
    "            return3_df.loc[j, 'gamma'] += (ret3_gamma/len(ten_splits[j]))\n",
    "            return3_df.loc[j, 'beta'] += (ret3_beta/len(ten_splits[j]))\n",
    "            \n",
    "            return5_df.loc[j, 'alpha'] += (ret5_alpha/len(ten_splits[j]))\n",
    "            return5_df.loc[j, 'gamma'] += (ret5_gamma/len(ten_splits[j]))\n",
    "            return5_df.loc[j, 'beta'] += (ret5_beta/len(ten_splits[j]))\n",
    "            \n",
    "            return10_df.loc[j, 'alpha'] += (ret10_alpha/len(ten_splits[j]))\n",
    "            return10_df.loc[j, 'gamma'] += (ret10_gamma/len(ten_splits[j]))\n",
    "            return10_df.loc[j, 'beta'] += (ret10_beta/len(ten_splits[j]))\n",
    "            \n",
    "            return14_df.loc[j, 'alpha'] += (ret14_alpha/len(ten_splits[j]))\n",
    "            return14_df.loc[j, 'gamma'] += (ret14_gamma/len(ten_splits[j]))\n",
    "            return14_df.loc[j, 'beta'] += (ret14_beta/len(ten_splits[j]))\n",
    "            \n",
    "            return20_df.loc[j, 'alpha'] += (ret20_alpha/len(ten_splits[j]))\n",
    "            return20_df.loc[j, 'gamma'] += (ret20_gamma/len(ten_splits[j]))\n",
    "            return20_df.loc[j, 'beta'] += (ret20_beta/len(ten_splits[j]))\n",
    "                \n",
    "            \n",
    "    # Get average value\n",
    "    return3_df['alpha'] /= 5\n",
    "    return3_df['beta'] /= 5\n",
    "    return3_df['gamma'] /= 5\n",
    "    return3_df.to_csv('GARCH_3.csv')\n",
    "    \n",
    "    return5_df['alpha'] /= 5\n",
    "    return5_df['beta'] /= 5\n",
    "    return5_df['gamma'] /= 5\n",
    "    return5_df.to_csv('GARCH_5.csv')    \n",
    "    \n",
    "    return10_df['alpha'] /= 5\n",
    "    return10_df['beta'] /= 5\n",
    "    return10_df['gamma'] /= 5\n",
    "    return10_df.to_csv('GARCH_10.csv')\n",
    "    \n",
    "    return14_df['alpha'] /= 5\n",
    "    return14_df['beta'] /= 5\n",
    "    return14_df['gamma'] /= 5\n",
    "    return14_df.to_csv('GARCH_14.csv')\n",
    "    \n",
    "    return20_df['alpha'] /= 5\n",
    "    return20_df['beta'] /= 5\n",
    "    return20_df['gamma'] /= 5\n",
    "    return20_df.to_csv('GARCH_20.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at year 1\n",
      "---> We are at decile of 0 consisting of 27 firms!\n",
      "---> We are at decile of 1 consisting of 27 firms!\n",
      "---> We are at decile of 2 consisting of 27 firms!\n",
      "---> We are at decile of 3 consisting of 27 firms!\n",
      "---> We are at decile of 4 consisting of 27 firms!\n",
      "---> We are at decile of 5 consisting of 26 firms!\n",
      "---> We are at decile of 6 consisting of 26 firms!\n",
      "---> We are at decile of 7 consisting of 26 firms!\n",
      "---> We are at decile of 8 consisting of 26 firms!\n",
      "---> We are at decile of 9 consisting of 26 firms!\n",
      "We are at year 2\n",
      "---> We are at decile of 0 consisting of 25 firms!\n",
      "---> We are at decile of 1 consisting of 25 firms!\n",
      "---> We are at decile of 2 consisting of 25 firms!\n",
      "---> We are at decile of 3 consisting of 25 firms!\n",
      "---> We are at decile of 4 consisting of 25 firms!\n",
      "---> We are at decile of 5 consisting of 25 firms!\n",
      "---> We are at decile of 6 consisting of 24 firms!\n",
      "---> We are at decile of 7 consisting of 24 firms!\n",
      "---> We are at decile of 8 consisting of 24 firms!\n",
      "---> We are at decile of 9 consisting of 24 firms!\n",
      "We are at year 3\n",
      "---> We are at decile of 0 consisting of 34 firms!\n",
      "---> We are at decile of 1 consisting of 34 firms!\n",
      "---> We are at decile of 2 consisting of 33 firms!\n",
      "---> We are at decile of 3 consisting of 33 firms!\n",
      "---> We are at decile of 4 consisting of 33 firms!\n",
      "---> We are at decile of 5 consisting of 33 firms!\n",
      "---> We are at decile of 6 consisting of 33 firms!\n",
      "---> We are at decile of 7 consisting of 33 firms!\n",
      "---> We are at decile of 8 consisting of 33 firms!\n",
      "---> We are at decile of 9 consisting of 33 firms!\n",
      "We are at year 4\n",
      "---> We are at decile of 0 consisting of 33 firms!\n",
      "---> We are at decile of 1 consisting of 33 firms!\n",
      "---> We are at decile of 2 consisting of 33 firms!\n",
      "---> We are at decile of 3 consisting of 33 firms!\n",
      "---> We are at decile of 4 consisting of 33 firms!\n",
      "---> We are at decile of 5 consisting of 33 firms!\n",
      "---> We are at decile of 6 consisting of 32 firms!\n",
      "---> We are at decile of 7 consisting of 32 firms!\n",
      "---> We are at decile of 8 consisting of 32 firms!\n",
      "---> We are at decile of 9 consisting of 32 firms!\n",
      "We are at year 5\n",
      "---> We are at decile of 0 consisting of 38 firms!\n",
      "---> We are at decile of 1 consisting of 38 firms!\n",
      "---> We are at decile of 2 consisting of 38 firms!\n",
      "---> We are at decile of 3 consisting of 38 firms!\n",
      "---> We are at decile of 4 consisting of 38 firms!\n",
      "---> We are at decile of 5 consisting of 38 firms!\n",
      "---> We are at decile of 6 consisting of 38 firms!\n",
      "---> We are at decile of 7 consisting of 38 firms!\n",
      "---> We are at decile of 8 consisting of 38 firms!\n",
      "---> We are at decile of 9 consisting of 37 firms!\n"
     ]
    }
   ],
   "source": [
    "cleaned_dfs = GenerateFeatures(PRICE_FILES, VOLUME_FILES)\n",
    "RenderList = Rearrange(cleaned_dfs)\n",
    "GetVolumeTraded(RenderList)\n",
    "GenerateTable_GARCH(RenderList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
