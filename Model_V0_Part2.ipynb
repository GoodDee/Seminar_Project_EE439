{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Modeling\n",
    "In this notebook, I will walkthrough the process of modelling after we got the data from part 1. I hope that we would see some useful results at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Many scikit-learn packages to import\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MA_diff_3</th>\n",
       "      <th>MA_diff_5</th>\n",
       "      <th>MA_diff_10</th>\n",
       "      <th>MA_diff_14</th>\n",
       "      <th>MA_diff_20</th>\n",
       "      <th>EMA_diff</th>\n",
       "      <th>MACD</th>\n",
       "      <th>...</th>\n",
       "      <th>STD_14</th>\n",
       "      <th>STD_20</th>\n",
       "      <th>Volume_Agent</th>\n",
       "      <th>Y_1</th>\n",
       "      <th>Y_3</th>\n",
       "      <th>Y_5</th>\n",
       "      <th>Y_10</th>\n",
       "      <th>Y_14</th>\n",
       "      <th>Y_20</th>\n",
       "      <th>Y_N_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>842.97</td>\n",
       "      <td>1686634.0</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>5.874</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.112857</td>\n",
       "      <td>1.1225</td>\n",
       "      <td>0.846747</td>\n",
       "      <td>-0.843428</td>\n",
       "      <td>...</td>\n",
       "      <td>19.004899</td>\n",
       "      <td>16.768455</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-03</td>\n",
       "      <td>832.63</td>\n",
       "      <td>2203218.0</td>\n",
       "      <td>-6.476667</td>\n",
       "      <td>-2.130</td>\n",
       "      <td>1.501</td>\n",
       "      <td>-0.558571</td>\n",
       "      <td>-0.6085</td>\n",
       "      <td>-0.271927</td>\n",
       "      <td>-1.046243</td>\n",
       "      <td>...</td>\n",
       "      <td>18.795705</td>\n",
       "      <td>16.548025</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-04</td>\n",
       "      <td>821.71</td>\n",
       "      <td>2244205.0</td>\n",
       "      <td>-12.130000</td>\n",
       "      <td>-3.898</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-0.884286</td>\n",
       "      <td>-1.2365</td>\n",
       "      <td>-1.336735</td>\n",
       "      <td>-2.064332</td>\n",
       "      <td>...</td>\n",
       "      <td>18.863764</td>\n",
       "      <td>16.388750</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-07</td>\n",
       "      <td>808.31</td>\n",
       "      <td>1749336.0</td>\n",
       "      <td>-11.553333</td>\n",
       "      <td>-8.750</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-1.770000</td>\n",
       "      <td>-1.1405</td>\n",
       "      <td>-2.543061</td>\n",
       "      <td>-3.907400</td>\n",
       "      <td>...</td>\n",
       "      <td>19.579607</td>\n",
       "      <td>17.186561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-08</td>\n",
       "      <td>811.69</td>\n",
       "      <td>1746730.0</td>\n",
       "      <td>-6.980000</td>\n",
       "      <td>-9.282</td>\n",
       "      <td>1.998</td>\n",
       "      <td>-1.765000</td>\n",
       "      <td>-1.0825</td>\n",
       "      <td>-1.950755</td>\n",
       "      <td>-5.037241</td>\n",
       "      <td>...</td>\n",
       "      <td>19.783006</td>\n",
       "      <td>17.660359</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Close     Volume  MA_diff_3  MA_diff_5  MA_diff_10  \\\n",
       "0  2008-01-02  842.97  1686634.0   0.590000      5.874       0.657   \n",
       "1  2008-01-03  832.63  2203218.0  -6.476667     -2.130       1.501   \n",
       "2  2008-01-04  821.71  2244205.0 -12.130000     -3.898       0.781   \n",
       "3  2008-01-07  808.31  1749336.0 -11.553333     -8.750       0.333   \n",
       "4  2008-01-08  811.69  1746730.0  -6.980000     -9.282       1.998   \n",
       "\n",
       "   MA_diff_14  MA_diff_20  EMA_diff      MACD  ...     STD_14     STD_20  \\\n",
       "0    0.112857      1.1225  0.846747 -0.843428  ...  19.004899  16.768455   \n",
       "1   -0.558571     -0.6085 -0.271927 -1.046243  ...  18.795705  16.548025   \n",
       "2   -0.884286     -1.2365 -1.336735 -2.064332  ...  18.863764  16.388750   \n",
       "3   -1.770000     -1.1405 -2.543061 -3.907400  ...  19.579607  17.186561   \n",
       "4   -1.765000     -1.0825 -1.950755 -5.037241  ...  19.783006  17.660359   \n",
       "\n",
       "   Volume_Agent  Y_1  Y_3  Y_5  Y_10  Y_14  Y_20  Y_N_1  \n",
       "0             1   -1   -1   -1    -1    -1    -1      1  \n",
       "1             1   -1   -1   -1    -1    -1    -1      1  \n",
       "2             1   -1    0   -1    -1    -1    -1      1  \n",
       "3             1    0   -1   -1    -1    -1     0      1  \n",
       "4             0    1   -1   -1    -1    -1     0      0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## First, we read the dataframe that we got from the last part (part 1)\n",
    "## Remember the rule of ML: analyze only training set (do not touch validating or testing set if not specified so)\n",
    "Train_df = pd.read_csv('SET_Train.csv')\n",
    "Validate_df = pd.read_csv('SET_Validate.csv')\n",
    "Test_a_df = pd.read_csv('SET_Test_a.csv')\n",
    "Test_b_df = pd.read_csv('SET_Test_b.csv')\n",
    "Train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    1117\n",
       " 1     720\n",
       "-1     604\n",
       "Name: Y_1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df['Y_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1047\n",
       "-1     765\n",
       " 0     629\n",
       "Name: Y_3, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df['Y_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1154\n",
       "-1     830\n",
       " 0     457\n",
       "Name: Y_5, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df['Y_5'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1293\n",
       "-1     846\n",
       " 0     302\n",
       "Name: Y_10, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df['Y_10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1337\n",
       "-1     851\n",
       " 0     253\n",
       "Name: Y_14, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df['Y_14'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1402\n",
       "-1     831\n",
       " 0     208\n",
       "Name: Y_20, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df['Y_20'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y_10</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y_1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>319</td>\n",
       "      <td>68</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368</td>\n",
       "      <td>168</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159</td>\n",
       "      <td>66</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y_10   -1    0    1\n",
       "Y_1                \n",
       "-1    319   68  217\n",
       " 0    368  168  581\n",
       " 1    159   66  495"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(Train_df['Y_1'], Train_df['Y_10']) # 40% in the diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y_14</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y_3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>455</td>\n",
       "      <td>80</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>87</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193</td>\n",
       "      <td>86</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y_14   -1   0    1\n",
       "Y_3               \n",
       "-1    455  80  230\n",
       " 0    203  87  339\n",
       " 1    193  86  768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(Train_df['Y_3'], Train_df['Y_14']) # 53% in the diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Y_20</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y_5</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>483</td>\n",
       "      <td>59</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152</td>\n",
       "      <td>74</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196</td>\n",
       "      <td>75</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Y_20   -1   0    1\n",
       "Y_5               \n",
       "-1    483  59  288\n",
       " 0    152  74  231\n",
       " 1    196  75  883"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(Train_df['Y_5'], Train_df['Y_20']) # 59% in the diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- For one-day ahead forecast, the most frequent class is \"sideway\" while \"up\" and \"down\" classes are roughly similar.  \n",
    "- For three-day, five-day and 14-day ahead forecast and beyond, \"sideway\" became the least popular class while \"up\" is the most popular class among the three.\n",
    "- Looking at cross-tab, different-period forecast followed the same prediction around 50% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MA_diff_3</th>\n",
       "      <th>MA_diff_5</th>\n",
       "      <th>MA_diff_10</th>\n",
       "      <th>MA_diff_14</th>\n",
       "      <th>MA_diff_20</th>\n",
       "      <th>EMA_diff</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>CCI_10</th>\n",
       "      <th>CCI_14</th>\n",
       "      <th>CCI_20</th>\n",
       "      <th>STD_3</th>\n",
       "      <th>STD_5</th>\n",
       "      <th>STD_10</th>\n",
       "      <th>STD_14</th>\n",
       "      <th>STD_20</th>\n",
       "      <th>Volume_Agent</th>\n",
       "      <th>Y_N_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2.441000e+03</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "      <td>2441.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1178.293695</td>\n",
       "      <td>7.406376e+06</td>\n",
       "      <td>0.368501</td>\n",
       "      <td>0.372335</td>\n",
       "      <td>0.374966</td>\n",
       "      <td>0.370038</td>\n",
       "      <td>0.365080</td>\n",
       "      <td>0.367274</td>\n",
       "      <td>2.516408</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>...</td>\n",
       "      <td>14.350821</td>\n",
       "      <td>16.589049</td>\n",
       "      <td>18.845889</td>\n",
       "      <td>7.976560</td>\n",
       "      <td>10.362944</td>\n",
       "      <td>14.606987</td>\n",
       "      <td>17.237003</td>\n",
       "      <td>20.663256</td>\n",
       "      <td>0.463335</td>\n",
       "      <td>-0.045063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>362.904923</td>\n",
       "      <td>5.205370e+06</td>\n",
       "      <td>7.243376</td>\n",
       "      <td>5.611197</td>\n",
       "      <td>3.889900</td>\n",
       "      <td>3.305590</td>\n",
       "      <td>2.799292</td>\n",
       "      <td>2.867838</td>\n",
       "      <td>14.407065</td>\n",
       "      <td>1.585529</td>\n",
       "      <td>...</td>\n",
       "      <td>79.799658</td>\n",
       "      <td>83.666191</td>\n",
       "      <td>86.737375</td>\n",
       "      <td>6.050765</td>\n",
       "      <td>6.864183</td>\n",
       "      <td>8.559796</td>\n",
       "      <td>9.550124</td>\n",
       "      <td>10.795102</td>\n",
       "      <td>0.498756</td>\n",
       "      <td>0.735249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>384.150000</td>\n",
       "      <td>9.056574e+05</td>\n",
       "      <td>-41.843333</td>\n",
       "      <td>-27.618000</td>\n",
       "      <td>-18.487000</td>\n",
       "      <td>-14.585000</td>\n",
       "      <td>-11.747000</td>\n",
       "      <td>-13.808023</td>\n",
       "      <td>-53.049231</td>\n",
       "      <td>-7.719244</td>\n",
       "      <td>...</td>\n",
       "      <td>-178.925342</td>\n",
       "      <td>-200.918770</td>\n",
       "      <td>-238.933328</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.826819</td>\n",
       "      <td>2.191589</td>\n",
       "      <td>2.476709</td>\n",
       "      <td>3.225144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>845.830000</td>\n",
       "      <td>3.665487e+06</td>\n",
       "      <td>-3.313333</td>\n",
       "      <td>-2.506000</td>\n",
       "      <td>-1.796000</td>\n",
       "      <td>-1.393571</td>\n",
       "      <td>-1.178500</td>\n",
       "      <td>-1.170292</td>\n",
       "      <td>-5.620914</td>\n",
       "      <td>-0.810094</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.163099</td>\n",
       "      <td>-50.848720</td>\n",
       "      <td>-52.379445</td>\n",
       "      <td>3.937795</td>\n",
       "      <td>5.911622</td>\n",
       "      <td>8.768859</td>\n",
       "      <td>10.601046</td>\n",
       "      <td>13.430422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1289.070000</td>\n",
       "      <td>6.316200e+06</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.813000</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.721500</td>\n",
       "      <td>0.792966</td>\n",
       "      <td>4.267453</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>...</td>\n",
       "      <td>26.615490</td>\n",
       "      <td>31.863177</td>\n",
       "      <td>34.632393</td>\n",
       "      <td>6.648301</td>\n",
       "      <td>8.690091</td>\n",
       "      <td>12.464816</td>\n",
       "      <td>15.033639</td>\n",
       "      <td>18.629973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1497.980000</td>\n",
       "      <td>9.743239e+06</td>\n",
       "      <td>4.763333</td>\n",
       "      <td>3.946000</td>\n",
       "      <td>2.868000</td>\n",
       "      <td>2.652143</td>\n",
       "      <td>2.352500</td>\n",
       "      <td>2.315792</td>\n",
       "      <td>12.987342</td>\n",
       "      <td>0.877887</td>\n",
       "      <td>...</td>\n",
       "      <td>83.083804</td>\n",
       "      <td>87.948493</td>\n",
       "      <td>90.336189</td>\n",
       "      <td>10.092078</td>\n",
       "      <td>12.503994</td>\n",
       "      <td>18.074873</td>\n",
       "      <td>21.068076</td>\n",
       "      <td>25.566598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1753.710000</td>\n",
       "      <td>5.294146e+07</td>\n",
       "      <td>27.453333</td>\n",
       "      <td>21.594000</td>\n",
       "      <td>17.557000</td>\n",
       "      <td>13.911429</td>\n",
       "      <td>8.057000</td>\n",
       "      <td>10.147395</td>\n",
       "      <td>30.595982</td>\n",
       "      <td>6.960438</td>\n",
       "      <td>...</td>\n",
       "      <td>174.382674</td>\n",
       "      <td>207.239309</td>\n",
       "      <td>241.354532</td>\n",
       "      <td>50.284455</td>\n",
       "      <td>53.863507</td>\n",
       "      <td>58.286524</td>\n",
       "      <td>67.345369</td>\n",
       "      <td>73.995076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Close        Volume    MA_diff_3    MA_diff_5   MA_diff_10  \\\n",
       "count  2441.000000  2.441000e+03  2441.000000  2441.000000  2441.000000   \n",
       "mean   1178.293695  7.406376e+06     0.368501     0.372335     0.374966   \n",
       "std     362.904923  5.205370e+06     7.243376     5.611197     3.889900   \n",
       "min     384.150000  9.056574e+05   -41.843333   -27.618000   -18.487000   \n",
       "25%     845.830000  3.665487e+06    -3.313333    -2.506000    -1.796000   \n",
       "50%    1289.070000  6.316200e+06     1.010000     0.884000     0.813000   \n",
       "75%    1497.980000  9.743239e+06     4.763333     3.946000     2.868000   \n",
       "max    1753.710000  5.294146e+07    27.453333    21.594000    17.557000   \n",
       "\n",
       "        MA_diff_14   MA_diff_20     EMA_diff         MACD    MACD_diff  ...  \\\n",
       "count  2441.000000  2441.000000  2441.000000  2441.000000  2441.000000  ...   \n",
       "mean      0.370038     0.365080     0.367274     2.516408     0.006069  ...   \n",
       "std       3.305590     2.799292     2.867838    14.407065     1.585529  ...   \n",
       "min     -14.585000   -11.747000   -13.808023   -53.049231    -7.719244  ...   \n",
       "25%      -1.393571    -1.178500    -1.170292    -5.620914    -0.810094  ...   \n",
       "50%       0.810714     0.721500     0.792966     4.267453     0.124999  ...   \n",
       "75%       2.652143     2.352500     2.315792    12.987342     0.877887  ...   \n",
       "max      13.911429     8.057000    10.147395    30.595982     6.960438  ...   \n",
       "\n",
       "            CCI_10       CCI_14       CCI_20        STD_3        STD_5  \\\n",
       "count  2441.000000  2441.000000  2441.000000  2441.000000  2441.000000   \n",
       "mean     14.350821    16.589049    18.845889     7.976560    10.362944   \n",
       "std      79.799658    83.666191    86.737375     6.050765     6.864183   \n",
       "min    -178.925342  -200.918770  -238.933328     0.090000     0.826819   \n",
       "25%     -50.163099   -50.848720   -52.379445     3.937795     5.911622   \n",
       "50%      26.615490    31.863177    34.632393     6.648301     8.690091   \n",
       "75%      83.083804    87.948493    90.336189    10.092078    12.503994   \n",
       "max     174.382674   207.239309   241.354532    50.284455    53.863507   \n",
       "\n",
       "            STD_10       STD_14       STD_20  Volume_Agent        Y_N_1  \n",
       "count  2441.000000  2441.000000  2441.000000   2441.000000  2441.000000  \n",
       "mean     14.606987    17.237003    20.663256      0.463335    -0.045063  \n",
       "std       8.559796     9.550124    10.795102      0.498756     0.735249  \n",
       "min       2.191589     2.476709     3.225144      0.000000    -1.000000  \n",
       "25%       8.768859    10.601046    13.430422      0.000000    -1.000000  \n",
       "50%      12.464816    15.033639    18.629973      0.000000     0.000000  \n",
       "75%      18.074873    21.068076    25.566598      1.000000     0.000000  \n",
       "max      58.286524    67.345369    73.995076      1.000000     1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "(For MA and EMA, most of values are very close to each other: as expected)  \n",
    "- For \"RSI\", the average value is 55, with min = 1.2, max = 99. (as expected because overtime degree of overbought and oversold should be cancelled out)   \n",
    "- For \"MACD\", the average value is 2.5 and median is 4.3, indicating left-skewed distribution of MACD. (Tail chance that the short-trend goes way below long-trend)  \n",
    "- For MOM1 - MOM14, the mean is very close to zero, indicating if you blindly trade stock every day, the average return that you should get is zero.  \n",
    "- For CCI_20, the average value is 18.8 while the median is 34, also indicating left-skewed distribution of CCI. (Tail chance that the index goes way below the trend in more than 2SD)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_y_1 = Train_df['Y_1']\n",
    "Train_y_3 = Train_df['Y_3']\n",
    "Train_y_5 = Train_df['Y_5']\n",
    "Train_y_10 = Train_df['Y_10']\n",
    "Train_y_14 = Train_df['Y_14']\n",
    "Train_y_20 = Train_df['Y_20']\n",
    "\n",
    "Test_y_1 = Validate_df['Y_1']\n",
    "Test_y_3 = Validate_df['Y_3']\n",
    "Test_y_5 = Validate_df['Y_5']\n",
    "Test_y_10 = Validate_df['Y_10']\n",
    "Test_y_14 = Validate_df['Y_14']\n",
    "Test_y_20 = Validate_df['Y_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df.drop(['Y_1', 'Y_3', 'Y_5', 'Y_10', 'Y_14', 'Y_20'], axis = 1, inplace = True)\n",
    "Validate_df.drop(['Y_1', 'Y_3', 'Y_5', 'Y_10', 'Y_14', 'Y_20'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have defined y at each different interval already, but we will define x as we go (to remind myself, I remove y from dataframe first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier (most frequent) training accuracy on 1 day ahead: 0.45759934453092993\n",
      "Dummy classifier (most frequent) prediction accuracy on 1 day ahead: 0.5591836734693878\n",
      "Dummy classifier (most frequent) training accuracy on 3 days ahead: 0.42892257271609996\n",
      "Dummy classifier (most frequent) prediction accuracy on 3 days ahead: 0.3224489795918367\n",
      "Dummy classifier (most frequent) training accuracy on 5 days ahead: 0.4727570667759115\n",
      "Dummy classifier (most frequent) prediction accuracy on 5 days ahead: 0.34285714285714286\n",
      "Dummy classifier (most frequent) training accuracy on 10 days ahead: 0.5297009422367882\n",
      "Dummy classifier (most frequent) prediction accuracy on 10 days ahead: 0.3346938775510204\n",
      "Dummy classifier (most frequent) training accuracy on 14 days ahead: 0.5477263416632527\n",
      "Dummy classifier (most frequent) prediction accuracy on 14 days ahead: 0.2938775510204082\n",
      "Dummy classifier (most frequent) training accuracy on 20 days ahead: 0.5743547726341663\n",
      "Dummy classifier (most frequent) prediction accuracy on 20 days ahead: 0.2816326530612245\n"
     ]
    }
   ],
   "source": [
    "## First, build the most fundamental benchmark model: dummy classifiers\n",
    "## I will build two versions: most-frequent version and stratified version\n",
    "## Most-frequent version is to measure accuracy on validating set\n",
    "## Stratified version is to report accuracy table -> Will do later if have to\n",
    "\n",
    "clf_dummy_mf_1 = DummyClassifier(strategy=\"most_frequent\")\n",
    "clf_dummy_mf_1.fit(Train_df, Train_y_1)\n",
    "print('Dummy classifier (most frequent) training accuracy on 1 day ahead:', clf_dummy_mf_1.score(Train_df, Train_y_1))\n",
    "print('Dummy classifier (most frequent) prediction accuracy on 1 day ahead:', clf_dummy_mf_1.score(Validate_df, Test_y_1))\n",
    "\n",
    "clf_dummy_mf_3 = DummyClassifier(strategy=\"most_frequent\")\n",
    "clf_dummy_mf_3.fit(Train_df, Train_y_3)\n",
    "print('Dummy classifier (most frequent) training accuracy on 3 days ahead:', clf_dummy_mf_3.score(Train_df, Train_y_3))\n",
    "print('Dummy classifier (most frequent) prediction accuracy on 3 days ahead:', clf_dummy_mf_3.score(Validate_df, Test_y_3))\n",
    "\n",
    "clf_dummy_mf_5 = DummyClassifier(strategy=\"most_frequent\")\n",
    "clf_dummy_mf_5.fit(Train_df, Train_y_5)\n",
    "print('Dummy classifier (most frequent) training accuracy on 5 days ahead:', clf_dummy_mf_5.score(Train_df, Train_y_5))\n",
    "print('Dummy classifier (most frequent) prediction accuracy on 5 days ahead:', clf_dummy_mf_5.score(Validate_df, Test_y_5))\n",
    "\n",
    "clf_dummy_mf_10 = DummyClassifier(strategy=\"most_frequent\")\n",
    "clf_dummy_mf_10.fit(Train_df, Train_y_10)\n",
    "print('Dummy classifier (most frequent) training accuracy on 10 days ahead:', clf_dummy_mf_10.score(Train_df, Train_y_10))\n",
    "print('Dummy classifier (most frequent) prediction accuracy on 10 days ahead:', clf_dummy_mf_10.score(Validate_df, Test_y_10))\n",
    "\n",
    "clf_dummy_mf_14 = DummyClassifier(strategy=\"most_frequent\")\n",
    "clf_dummy_mf_14.fit(Train_df, Train_y_14)\n",
    "print('Dummy classifier (most frequent) training accuracy on 14 days ahead:', clf_dummy_mf_14.score(Train_df, Train_y_14))\n",
    "print('Dummy classifier (most frequent) prediction accuracy on 14 days ahead:', clf_dummy_mf_14.score(Validate_df, Test_y_14))\n",
    "\n",
    "clf_dummy_mf_20 = DummyClassifier(strategy=\"most_frequent\")\n",
    "clf_dummy_mf_20.fit(Train_df, Train_y_20)\n",
    "print('Dummy classifier (most frequent) training accuracy on 20 days ahead:', clf_dummy_mf_20.score(Train_df, Train_y_20))\n",
    "print('Dummy classifier (most frequent) prediction accuracy on 20 days ahead:', clf_dummy_mf_20.score(Validate_df, Test_y_20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression on lagged training accuracy on 1 day ahead: 0.45759934453092993\n",
      "Logistic regression on lagged prediction accuracy on 1 day ahead: 0.5591836734693878\n",
      "Logistic regression on lagged training accuracy on 3 days ahead: 0.42892257271609996\n",
      "Logistic regression on lagged prediction accuracy on 3 days ahead: 0.3224489795918367\n",
      "Logistic regression on lagged training accuracy on 5 days ahead: 0.4727570667759115\n",
      "Logistic regression on lagged prediction accuracy on 5 days ahead: 0.34285714285714286\n",
      "Logistic regression on lagged training accuracy on 10 days ahead: 0.5297009422367882\n",
      "Logistic regression on lagged prediction accuracy on 10 days ahead: 0.3346938775510204\n",
      "Logistic regression on lagged training accuracy on 3 days ahead: 0.5477263416632527\n",
      "Logistic regression on lagged prediction accuracy on 3 days ahead: 0.2938775510204082\n",
      "Logistic regression on lagged training accuracy on 3 days ahead: 0.5743547726341663\n",
      "Logistic regression on lagged prediction accuracy on 3 days ahead: 0.2816326530612245\n"
     ]
    }
   ],
   "source": [
    "## Second, build a slightly smarter version: logistic regression on a lagged dependent variable\n",
    "## For visualizing feature importances, use standardized parameters instead\n",
    "## Source: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "X_train = Train_df[['Y_N_1']]\n",
    "X_test = Validate_df[['Y_N_1']]\n",
    "clf_LR_1 = LogisticRegression(random_state=0).fit(X_train, Train_y_1)\n",
    "print('Logistic regression on lagged training accuracy on 1 day ahead:', clf_LR_1.score(X_train, Train_y_1))\n",
    "print('Logistic regression on lagged prediction accuracy on 1 day ahead:', clf_LR_1.score(X_test, Test_y_1))\n",
    "\n",
    "clf_LR_3 = LogisticRegression(random_state=0).fit(X_train, Train_y_3)\n",
    "print('Logistic regression on lagged training accuracy on 3 days ahead:', clf_LR_3.score(X_train, Train_y_3))\n",
    "print('Logistic regression on lagged prediction accuracy on 3 days ahead:', clf_LR_3.score(X_test, Test_y_3))\n",
    "\n",
    "clf_LR_5 = LogisticRegression(random_state=0).fit(X_train, Train_y_5)\n",
    "print('Logistic regression on lagged training accuracy on 5 days ahead:', clf_LR_5.score(X_train, Train_y_5))\n",
    "print('Logistic regression on lagged prediction accuracy on 5 days ahead:', clf_LR_5.score(X_test, Test_y_5))\n",
    "\n",
    "clf_LR_10 = LogisticRegression(random_state=0).fit(X_train, Train_y_10)\n",
    "print('Logistic regression on lagged training accuracy on 10 days ahead:', clf_LR_10.score(X_train, Train_y_10))\n",
    "print('Logistic regression on lagged prediction accuracy on 10 days ahead:', clf_LR_10.score(X_test, Test_y_10))\n",
    "\n",
    "clf_LR_14 = LogisticRegression(random_state=0).fit(X_train, Train_y_14)\n",
    "print('Logistic regression on lagged training accuracy on 3 days ahead:', clf_LR_14.score(X_train, Train_y_14))\n",
    "print('Logistic regression on lagged prediction accuracy on 3 days ahead:', clf_LR_14.score(X_test, Test_y_14))\n",
    "\n",
    "clf_LR_20 = LogisticRegression(random_state=0).fit(X_train, Train_y_20)\n",
    "print('Logistic regression on lagged training accuracy on 3 days ahead:', clf_LR_20.score(X_train, Train_y_20))\n",
    "print('Logistic regression on lagged prediction accuracy on 3 days ahead:', clf_LR_20.score(X_test, Test_y_20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = Train_df[['Y_N_1', 'EMA_diff', 'MACD', 'MOM1', 'RSI', 'MACD_diff', 'Volume_Agent']]\n",
    "X_train_3 = Train_df[['MA_diff_3', 'EMA_diff', 'MACD', 'MOM3', 'RSI', 'MACD_diff', 'CCI_3', 'STD_3', 'Volume_Agent']]\n",
    "X_train_5 = Train_df[['MA_diff_5', 'EMA_diff', 'MACD', 'MOM5', 'RSI', 'MACD_diff', 'CCI_5', 'STD_5', 'Volume_Agent']]\n",
    "X_train_10 = Train_df[['MA_diff_10', 'EMA_diff', 'MACD', 'MOM10', 'RSI', 'MACD_diff', 'CCI_10', 'STD_10', 'Volume_Agent']]\n",
    "X_train_14 = Train_df[['MA_diff_14', 'EMA_diff', 'MACD', 'MOM14', 'RSI', 'MACD_diff', 'CCI_14', 'STD_14', 'Volume_Agent']]\n",
    "X_train_20 = Train_df[['MA_diff_20', 'EMA_diff', 'MACD', 'MOM20', 'RSI', 'MACD_diff', 'CCI_20', 'STD_20', 'Volume_Agent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1 = Validate_df[['Y_N_1', 'EMA_diff', 'MACD', 'MOM1', 'RSI', 'MACD_diff', 'Volume_Agent']]\n",
    "X_test_3 = Validate_df[['MA_diff_3', 'EMA_diff', 'MACD', 'MOM3', 'RSI', 'MACD_diff', 'CCI_3', 'STD_3', 'Volume_Agent']]\n",
    "X_test_5 = Validate_df[['MA_diff_5', 'EMA_diff', 'MACD', 'MOM5', 'RSI', 'MACD_diff', 'CCI_5', 'STD_5', 'Volume_Agent']]\n",
    "X_test_10 = Validate_df[['MA_diff_10', 'EMA_diff', 'MACD', 'MOM10', 'RSI', 'MACD_diff', 'CCI_10', 'STD_10', 'Volume_Agent']]\n",
    "X_test_14 = Validate_df[['MA_diff_14', 'EMA_diff', 'MACD', 'MOM14', 'RSI', 'MACD_diff', 'CCI_14', 'STD_14', 'Volume_Agent']]\n",
    "X_test_20 = Validate_df[['MA_diff_20', 'EMA_diff', 'MACD', 'MOM20', 'RSI', 'MACD_diff', 'CCI_20', 'STD_20', 'Volume_Agent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression (all features) training accuracy on 1 day ahead: 0.45759934453092993\n",
      "Logistic regression (all features) prediction accuracy on 1 day ahead: 0.5591836734693878\n",
      "Logistic regression (all features)  training accuracy on 3 days ahead: 0.42892257271609996\n",
      "Logistic regression (all features) prediction accuracy on 3 days ahead: 0.3224489795918367\n",
      "Logistic regression (all features) training accuracy on 5 days ahead: 0.4727570667759115\n",
      "Logistic regression (all features) prediction accuracy on 5 days ahead: 0.34285714285714286\n"
     ]
    }
   ],
   "source": [
    "# Let's run logistic regression with at max 9 features\n",
    "\n",
    "clf_LR_all_1 = LogisticRegression(random_state=0, multi_class = \"multinomial\", C = 10**(-6)).fit(X_train_1, Train_y_1)\n",
    "print('Logistic regression (all features) training accuracy on 1 day ahead:', clf_LR_all_1.score(X_train_1, Train_y_1))\n",
    "print('Logistic regression (all features) prediction accuracy on 1 day ahead:', clf_LR_all_1.score(X_test_1, Test_y_1))\n",
    "\n",
    "clf_LR_all_3 = LogisticRegression(random_state=0, multi_class = \"multinomial\", C = 10**(-6)).fit(X_train_3, Train_y_3)\n",
    "print('Logistic regression (all features)  training accuracy on 3 days ahead:', clf_LR_all_3.score(X_train_3, Train_y_3))\n",
    "print('Logistic regression (all features) prediction accuracy on 3 days ahead:', clf_LR_all_3.score(X_test_3, Test_y_3))\n",
    "\n",
    "clf_LR_all_5 = LogisticRegression(random_state=0, multi_class = \"multinomial\", C = 10**(-6)).fit(X_train_5, Train_y_5)\n",
    "print('Logistic regression (all features) training accuracy on 5 days ahead:', clf_LR_all_5.score(X_train_5, Train_y_5))\n",
    "print('Logistic regression (all features) prediction accuracy on 5 days ahead:', clf_LR_all_5.score(X_test_5, Test_y_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression (all features) training accuracy on 10 day ahead: 0.5276526013928717\n",
      "Logistic regression (all features) prediction accuracy on 10 day ahead: 0.3306122448979592\n",
      "Logistic regression (all features)  training accuracy on 14 days ahead: 0.5477263416632527\n",
      "Logistic regression (all features) prediction accuracy on 14 days ahead: 0.2979591836734694\n",
      "Logistic regression (all features) training accuracy on 20 days ahead: 0.5743547726341663\n",
      "Logistic regression (all features) prediction accuracy on 20 days ahead: 0.2816326530612245\n"
     ]
    }
   ],
   "source": [
    "# Let's run logistic regression with at max 9 features\n",
    "\n",
    "clf_LR_all_10 = LogisticRegression(random_state=0, multi_class = \"multinomial\", C = 10**(-6)).fit(X_train_10, Train_y_10)\n",
    "print('Logistic regression (all features) training accuracy on 10 day ahead:', clf_LR_all_10.score(X_train_10, Train_y_10))\n",
    "print('Logistic regression (all features) prediction accuracy on 10 day ahead:', clf_LR_all_10.score(X_test_10, Test_y_10))\n",
    "\n",
    "clf_LR_all_14 = LogisticRegression(random_state=0, multi_class = \"multinomial\", C = 10**(-6)).fit(X_train_14, Train_y_14)\n",
    "print('Logistic regression (all features)  training accuracy on 14 days ahead:', clf_LR_all_14.score(X_train_14, Train_y_14))\n",
    "print('Logistic regression (all features) prediction accuracy on 14 days ahead:', clf_LR_all_14.score(X_test_14, Test_y_14))\n",
    "\n",
    "clf_LR_all_20 = LogisticRegression(random_state=0, multi_class = \"multinomial\", C = 10**(-6)).fit(X_train_20, Train_y_20)\n",
    "print('Logistic regression (all features) training accuracy on 20 days ahead:', clf_LR_all_20.score(X_train_20, Train_y_20))\n",
    "print('Logistic regression (all features) prediction accuracy on 20 days ahead:', clf_LR_all_20.score(X_test_20, Test_y_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT (all features) training accuracy on 1 day ahead: 0.47931175747644406\n",
      "DT (all features) prediction accuracy on 1 day ahead: 0.5224489795918368\n",
      "DT (all features)  training accuracy on 3 days ahead: 0.4559606718557968\n",
      "DT (all features) prediction accuracy on 3 days ahead: 0.37142857142857144\n",
      "DT (all features) training accuracy on 5 days ahead: 0.5018435067595248\n",
      "DT (all features) prediction accuracy on 5 days ahead: 0.3795918367346939\n",
      "DT (all features) training accuracy on 10 day ahead: 0.5571487095452683\n",
      "DT (all features) prediction accuracy on 10 day ahead: 0.3183673469387755\n",
      "DT (all features) training accuracy on 14 days ahead: 0.5661614092585007\n",
      "DT (all features) prediction accuracy on 14 days ahead: 0.3877551020408163\n",
      "DT (all features) training accuracy on 20 day ahead: 0.5989348627611635\n",
      "DT (all features) prediction accuracy on 20 day ahead: 0.4489795918367347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_LR_all_1 = DecisionTreeClassifier(random_state=0, max_features = \"sqrt\", max_depth = 6, min_weight_fraction_leaf = 0.05).fit(X_train_1, Train_y_1)\n",
    "print('DT (all features) training accuracy on 1 day ahead:', clf_LR_all_1.score(X_train_1, Train_y_1))\n",
    "print('DT (all features) prediction accuracy on 1 day ahead:', clf_LR_all_1.score(X_test_1, Test_y_1))\n",
    "\n",
    "clf_LR_all_3 = DecisionTreeClassifier(random_state=0, max_features = \"sqrt\", max_depth = 6, min_weight_fraction_leaf = 0.05).fit(X_train_3, Train_y_3)\n",
    "print('DT (all features)  training accuracy on 3 days ahead:', clf_LR_all_3.score(X_train_3, Train_y_3))\n",
    "print('DT (all features) prediction accuracy on 3 days ahead:', clf_LR_all_3.score(X_test_3, Test_y_3))\n",
    "\n",
    "clf_LR_all_5 = DecisionTreeClassifier(random_state=0, max_features = \"sqrt\", max_depth = 6, min_weight_fraction_leaf = 0.05).fit(X_train_5, Train_y_5)\n",
    "print('DT (all features) training accuracy on 5 days ahead:', clf_LR_all_5.score(X_train_5, Train_y_5))\n",
    "print('DT (all features) prediction accuracy on 5 days ahead:', clf_LR_all_5.score(X_test_5, Test_y_5))\n",
    "\n",
    "clf_LR_all_10 = DecisionTreeClassifier(random_state=0, max_features = \"sqrt\", max_depth = 6, min_weight_fraction_leaf = 0.05).fit(X_train_10, Train_y_10)\n",
    "print('DT (all features) training accuracy on 10 day ahead:', clf_LR_all_10.score(X_train_10, Train_y_10))\n",
    "print('DT (all features) prediction accuracy on 10 day ahead:', clf_LR_all_10.score(X_test_10, Test_y_10))\n",
    "\n",
    "clf_LR_all_14 = DecisionTreeClassifier(random_state=0, max_features = \"sqrt\", max_depth = 6, min_weight_fraction_leaf = 0.05).fit(X_train_14, Train_y_14)\n",
    "print('DT (all features) training accuracy on 14 days ahead:', clf_LR_all_14.score(X_train_14, Train_y_14))\n",
    "print('DT (all features) prediction accuracy on 14 days ahead:', clf_LR_all_14.score(X_test_14, Test_y_14))\n",
    "\n",
    "clf_LR_all_20 = DecisionTreeClassifier(random_state=0, max_features = \"sqrt\", max_depth = 6, min_weight_fraction_leaf = 0.05).fit(X_train_20, Train_y_20)\n",
    "print('DT (all features) training accuracy on 20 day ahead:', clf_LR_all_20.score(X_train_20, Train_y_20))\n",
    "print('DT (all features) prediction accuracy on 20 day ahead:', clf_LR_all_20.score(X_test_20, Test_y_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF (all features) training accuracy on 1 day ahead: 0.6419500204834084\n",
      "RF (all features) prediction accuracy on 1 day ahead: 0.46530612244897956\n",
      "RF (all features)  training accuracy on 3 days ahead: 0.6894715280622695\n",
      "RF (all features) prediction accuracy on 3 days ahead: 0.3020408163265306\n",
      "RF (all features) training accuracy on 5 days ahead: 0.6669397787791889\n",
      "RF (all features) prediction accuracy on 5 days ahead: 0.363265306122449\n",
      "RF (all features) training accuracy on 10 days ahead: 0.7042195821384678\n",
      "RF (all features) prediction accuracy on 10 days ahead: 0.3306122448979592\n",
      "RF (all features) training accuracy on 14 days ahead: 0.7505120852109791\n",
      "RF (all features) prediction accuracy on 14 days ahead: 0.4204081632653061\n",
      "RF (all features) training accuracy on 20 days ahead: 0.7795985251945924\n",
      "RF (all features) prediction accuracy on 20 days ahead: 0.46122448979591835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_LR_all_1 = RandomForestClassifier(random_state=0, max_depth = 10, min_weight_fraction_leaf = 0.005).fit(X_train_1, Train_y_1)\n",
    "print('RF (all features) training accuracy on 1 day ahead:', clf_LR_all_1.score(X_train_1, Train_y_1))\n",
    "print('RF (all features) prediction accuracy on 1 day ahead:', clf_LR_all_1.score(X_test_1, Test_y_1))\n",
    "\n",
    "clf_LR_all_3 = RandomForestClassifier(random_state=0, max_depth = 10, min_weight_fraction_leaf = 0.005).fit(X_train_3, Train_y_3)\n",
    "print('RF (all features)  training accuracy on 3 days ahead:', clf_LR_all_3.score(X_train_3, Train_y_3))\n",
    "print('RF (all features) prediction accuracy on 3 days ahead:', clf_LR_all_3.score(X_test_3, Test_y_3))\n",
    "\n",
    "clf_LR_all_5 = RandomForestClassifier(random_state=0, max_depth = 10, min_weight_fraction_leaf = 0.005).fit(X_train_5, Train_y_5)\n",
    "print('RF (all features) training accuracy on 5 days ahead:', clf_LR_all_5.score(X_train_5, Train_y_5))\n",
    "print('RF (all features) prediction accuracy on 5 days ahead:', clf_LR_all_5.score(X_test_5, Test_y_5))\n",
    "\n",
    "clf_LR_all_10 = RandomForestClassifier(random_state=0, max_depth = 10, min_weight_fraction_leaf = 0.005).fit(X_train_10, Train_y_10)\n",
    "print('RF (all features) training accuracy on 10 days ahead:', clf_LR_all_10.score(X_train_10, Train_y_10))\n",
    "print('RF (all features) prediction accuracy on 10 days ahead:', clf_LR_all_10.score(X_test_10, Test_y_10))\n",
    "\n",
    "clf_LR_all_14 = RandomForestClassifier(random_state=0, max_depth = 10, min_weight_fraction_leaf = 0.005).fit(X_train_14, Train_y_14)\n",
    "print('RF (all features) training accuracy on 14 days ahead:', clf_LR_all_14.score(X_train_14, Train_y_14))\n",
    "print('RF (all features) prediction accuracy on 14 days ahead:', clf_LR_all_14.score(X_test_14, Test_y_14))\n",
    "\n",
    "clf_LR_all_20 = RandomForestClassifier(random_state=0, max_depth = 10, min_weight_fraction_leaf = 0.005).fit(X_train_20, Train_y_20)\n",
    "print('RF (all features) training accuracy on 20 days ahead:', clf_LR_all_20.score(X_train_20, Train_y_20))\n",
    "print('RF (all features) prediction accuracy on 20 days ahead:', clf_LR_all_20.score(X_test_20, Test_y_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_y_1 = clf_LR_all_1.predict(X_test_1)\n",
    "Pred_y_3 = clf_LR_all_3.predict(X_test_3)\n",
    "Pred_y_5 = clf_LR_all_5.predict(X_test_5)\n",
    "Pred_y_10 = clf_LR_all_10.predict(X_test_10)\n",
    "Pred_y_14 = clf_LR_all_14.predict(X_test_14)\n",
    "Pred_y_20 = clf_LR_all_20.predict(X_test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.15      0.08      0.11        60\n",
      "           0       0.58      0.69      0.63       137\n",
      "           1       0.29      0.31      0.30        48\n",
      "\n",
      "    accuracy                           0.47       245\n",
      "   macro avg       0.34      0.36      0.35       245\n",
      "weighted avg       0.42      0.47      0.44       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Test_y_1, Pred_y_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.36      0.34      0.35        95\n",
      "           0       0.30      0.13      0.18        71\n",
      "           1       0.26      0.42      0.32        79\n",
      "\n",
      "    accuracy                           0.30       245\n",
      "   macro avg       0.31      0.29      0.28       245\n",
      "weighted avg       0.31      0.30      0.29       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_3, Pred_y_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.29      0.34       103\n",
      "           0       0.00      0.00      0.00        58\n",
      "           1       0.35      0.70      0.46        84\n",
      "\n",
      "    accuracy                           0.36       245\n",
      "   macro avg       0.25      0.33      0.27       245\n",
      "weighted avg       0.29      0.36      0.30       245\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_5, Pred_y_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.22      0.29       127\n",
      "           0       0.00      0.00      0.00        36\n",
      "           1       0.30      0.65      0.41        82\n",
      "\n",
      "    accuracy                           0.33       245\n",
      "   macro avg       0.24      0.29      0.23       245\n",
      "weighted avg       0.31      0.33      0.29       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_10, Pred_y_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.37      0.45       128\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.34      0.78      0.47        72\n",
      "\n",
      "    accuracy                           0.42       245\n",
      "   macro avg       0.31      0.38      0.31       245\n",
      "weighted avg       0.40      0.42      0.37       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_14, Pred_y_14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.37      0.49       145\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.35      0.86      0.50        69\n",
      "\n",
      "    accuracy                           0.46       245\n",
      "   macro avg       0.35      0.41      0.33       245\n",
      "weighted avg       0.52      0.46      0.43       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_20, Pred_y_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0289022 , 0.20393818, 0.19167446, 0.19947846, 0.18255213,\n",
       "       0.16817808, 0.0252765 ])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR_all_1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11867165, 0.13744927, 0.14360675, 0.12186161, 0.13869216,\n",
       "       0.11188888, 0.10162636, 0.1101321 , 0.01607122])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR_all_3.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10763555, 0.12147414, 0.13819545, 0.12357743, 0.1486735 ,\n",
       "       0.11341031, 0.10482803, 0.13060396, 0.01160163])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR_all_5.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12285178, 0.13636612, 0.12918539, 0.12414469, 0.1324066 ,\n",
       "       0.09216624, 0.09316876, 0.15127436, 0.01843605])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR_all_10.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12606207, 0.11283539, 0.1381796 , 0.14343982, 0.12970229,\n",
       "       0.07100453, 0.08417255, 0.17552063, 0.01908312])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR_all_14.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10104805, 0.0927546 , 0.13779034, 0.14643275, 0.1339007 ,\n",
       "       0.08880395, 0.09542577, 0.19224921, 0.01159462])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_LR_all_20.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT (all features) training accuracy on 1 day ahead: 0.546497337156903\n",
      "GBDT (all features) prediction accuracy on 1 day ahead: 0.46938775510204084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_GT_all_1 = GradientBoostingClassifier(random_state=0, max_depth = 5, min_weight_fraction_leaf = 0.2, learning_rate = 0.5).fit(X_train_1, Train_y_1)\n",
    "print('GBDT (all features) training accuracy on 1 day ahead:', clf_GT_all_1.score(X_train_1, Train_y_1))\n",
    "print('GBDT (all features) prediction accuracy on 1 day ahead:',clf_GT_all_1.score(X_test_1, Test_y_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT (all features) training accuracy on 3 day ahead: 0.5776321179844326\n",
      "GBDT (all features) prediction accuracy on 3 day ahead: 0.33877551020408164\n"
     ]
    }
   ],
   "source": [
    "clf_GT_all_3 = GradientBoostingClassifier(random_state=0, max_depth = 5, min_weight_fraction_leaf = 0.2, learning_rate = 0.5).fit(X_train_3, Train_y_3)\n",
    "print('GBDT (all features) training accuracy on 3 day ahead:', clf_GT_all_3.score(X_train_3, Train_y_3))\n",
    "print('GBDT (all features) prediction accuracy on 3 day ahead:',clf_GT_all_3.score(X_test_3, Test_y_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT (all features) training accuracy on 5 day ahead: 0.605489553461696\n",
      "GBDT (all features) prediction accuracy on 5 day ahead: 0.33877551020408164\n"
     ]
    }
   ],
   "source": [
    "clf_GT_all_5 = GradientBoostingClassifier(random_state=0, max_depth = 5, min_weight_fraction_leaf = 0.2, learning_rate = 0.5).fit(X_train_5, Train_y_5)\n",
    "print('GBDT (all features) training accuracy on 5 day ahead:', clf_GT_all_5.score(X_train_5, Train_y_5))\n",
    "print('GBDT (all features) prediction accuracy on 5 day ahead:',clf_GT_all_5.score(X_test_5, Test_y_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT (all features) training accuracy on 10 day ahead: 0.6423596886521917\n",
      "GBDT (all features) prediction accuracy on 10 day ahead: 0.3469387755102041\n"
     ]
    }
   ],
   "source": [
    "clf_GT_all_10 = GradientBoostingClassifier(random_state=0, max_depth = 5, min_weight_fraction_leaf = 0.2, learning_rate = 0.5).fit(X_train_10, Train_y_10)\n",
    "print('GBDT (all features) training accuracy on 10 day ahead:', clf_GT_all_10.score(X_train_10, Train_y_10))\n",
    "print('GBDT (all features) prediction accuracy on 10 day ahead:',clf_GT_all_10.score(X_test_10, Test_y_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT (all features) training accuracy on 14 day ahead: 0.6583367472347399\n",
      "GBDT (all features) prediction accuracy on 14 day ahead: 0.4204081632653061\n"
     ]
    }
   ],
   "source": [
    "clf_GT_all_14 = GradientBoostingClassifier(random_state=0, max_depth = 5, min_weight_fraction_leaf = 0.2, learning_rate = 0.5).fit(X_train_14, Train_y_14)\n",
    "print('GBDT (all features) training accuracy on 14 day ahead:', clf_GT_all_14.score(X_train_14, Train_y_14))\n",
    "print('GBDT (all features) prediction accuracy on 14 day ahead:',clf_GT_all_14.score(X_test_14, Test_y_14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT (all features) training accuracy on 20 day ahead: 0.6796394920114707\n",
      "GBDT (all features) prediction accuracy on 20 day ahead: 0.4857142857142857\n"
     ]
    }
   ],
   "source": [
    "clf_GT_all_20 = GradientBoostingClassifier(random_state=0, max_depth = 5, min_weight_fraction_leaf = 0.2, learning_rate = 0.5).fit(X_train_20, Train_y_20)\n",
    "print('GBDT (all features) training accuracy on 20 day ahead:', clf_GT_all_20.score(X_train_20, Train_y_20))\n",
    "print('GBDT (all features) prediction accuracy on 20 day ahead:',clf_GT_all_20.score(X_test_20, Test_y_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_y_1 = clf_GT_all_1.predict(X_test_1)\n",
    "Pred_y_3 = clf_GT_all_3.predict(X_test_3)\n",
    "Pred_y_5 = clf_GT_all_5.predict(X_test_5)\n",
    "Pred_y_10 = clf_GT_all_10.predict(X_test_10)\n",
    "Pred_y_14 = clf_GT_all_14.predict(X_test_14)\n",
    "Pred_y_20 = clf_GT_all_20.predict(X_test_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.29      0.23      0.26        60\n",
      "           0       0.60      0.66      0.63       137\n",
      "           1       0.22      0.21      0.22        48\n",
      "\n",
      "    accuracy                           0.47       245\n",
      "   macro avg       0.37      0.37      0.37       245\n",
      "weighted avg       0.45      0.47      0.46       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_1, Pred_y_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.42      0.34      0.37        95\n",
      "           0       0.33      0.18      0.23        71\n",
      "           1       0.30      0.48      0.37        79\n",
      "\n",
      "    accuracy                           0.34       245\n",
      "   macro avg       0.35      0.33      0.32       245\n",
      "weighted avg       0.35      0.34      0.33       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_3, Pred_y_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      0.29      0.34       103\n",
      "           0       0.24      0.07      0.11        58\n",
      "           1       0.32      0.58      0.42        84\n",
      "\n",
      "    accuracy                           0.34       245\n",
      "   macro avg       0.32      0.31      0.29       245\n",
      "weighted avg       0.33      0.34      0.31       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_5, Pred_y_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.26      0.32       127\n",
      "           0       0.40      0.06      0.10        36\n",
      "           1       0.31      0.61      0.41        82\n",
      "\n",
      "    accuracy                           0.35       245\n",
      "   macro avg       0.37      0.31      0.28       245\n",
      "weighted avg       0.38      0.35      0.32       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_10, Pred_y_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.33      0.44       128\n",
      "           0       0.12      0.02      0.04        45\n",
      "           1       0.34      0.83      0.49        72\n",
      "\n",
      "    accuracy                           0.42       245\n",
      "   macro avg       0.38      0.39      0.32       245\n",
      "weighted avg       0.48      0.42      0.38       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_14, Pred_y_14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.43      0.55       145\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.35      0.81      0.49        69\n",
      "\n",
      "    accuracy                           0.49       245\n",
      "   macro avg       0.37      0.42      0.35       245\n",
      "weighted avg       0.55      0.49      0.46       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_y_20, Pred_y_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.29827194, 0.17183633, 0.19990629, 0.15997652,\n",
       "       0.16100166, 0.00900725])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GT_all_1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10435695, 0.11534909, 0.16439193, 0.14161082, 0.15073945,\n",
       "       0.08508032, 0.09469754, 0.12505739, 0.01871651])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GT_all_3.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1090932 , 0.12614487, 0.15802491, 0.15340729, 0.1269216 ,\n",
       "       0.07227506, 0.09980479, 0.14222659, 0.01210169])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GT_all_5.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08089871, 0.10088227, 0.14429805, 0.11331059, 0.15046714,\n",
       "       0.09380513, 0.09237344, 0.18655525, 0.0374094 ])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GT_all_10.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07471256, 0.07096399, 0.14524494, 0.18286065, 0.10304173,\n",
       "       0.05823706, 0.08481881, 0.2546925 , 0.02542777])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GT_all_14.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07911951, 0.08905021, 0.12365312, 0.12967339, 0.13499752,\n",
       "       0.10396411, 0.08518436, 0.24679956, 0.00755822])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GT_all_20.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test data from 2019 to report in paper\n",
    "Test_y_1 = Test_a_df['Y_1']\n",
    "Test_y_3 = Test_a_df['Y_3']\n",
    "Test_y_5 = Test_a_df['Y_5']\n",
    "Test_y_10 = Test_a_df['Y_10']\n",
    "Test_y_14 = Test_a_df['Y_14']\n",
    "Test_y_20 = Test_a_df['Y_20']\n",
    "\n",
    "X_test_1 = Test_a_df[['Y_N_1', 'EMA_diff', 'MACD', 'MOM1', 'RSI', 'MACD_diff', 'Volume_Agent']]\n",
    "X_test_3 =Test_a_df[['MA_diff_3', 'EMA_diff', 'MACD', 'MOM3', 'RSI', 'MACD_diff', 'CCI_3', 'STD_3', 'Volume_Agent']]\n",
    "X_test_5 = Test_a_df[['MA_diff_5', 'EMA_diff', 'MACD', 'MOM5', 'RSI', 'MACD_diff', 'CCI_5', 'STD_5', 'Volume_Agent']]\n",
    "X_test_10 = Test_a_df[['MA_diff_10', 'EMA_diff', 'MACD', 'MOM10', 'RSI', 'MACD_diff', 'CCI_10', 'STD_10', 'Volume_Agent']]\n",
    "X_test_14 = Test_a_df[['MA_diff_14', 'EMA_diff', 'MACD', 'MOM14', 'RSI', 'MACD_diff', 'CCI_14', 'STD_14', 'Volume_Agent']]\n",
    "X_test_20 = Test_a_df[['MA_diff_20', 'EMA_diff', 'MACD', 'MOM20', 'RSI', 'MACD_diff', 'CCI_20', 'STD_20', 'Volume_Agent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5390946502057613\n",
      "0.34156378600823045\n",
      "0.3333333333333333\n",
      "0.4074074074074074\n",
      "0.45267489711934156\n",
      "0.4567901234567901\n"
     ]
    }
   ],
   "source": [
    "print(clf_LR_all_1.score(X_test_1, Test_y_1))\n",
    "print(clf_LR_all_3.score(X_test_3, Test_y_3))\n",
    "print(clf_LR_all_5.score(X_test_5, Test_y_5))\n",
    "print(clf_LR_all_10.score(X_test_10, Test_y_10))\n",
    "print(clf_LR_all_14.score(X_test_14, Test_y_14))\n",
    "print(clf_LR_all_20.score(X_test_20, Test_y_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48559670781893005\n",
      "0.3292181069958848\n",
      "0.32510288065843623\n",
      "0.4074074074074074\n",
      "0.46502057613168724\n",
      "0.48148148148148145\n"
     ]
    }
   ],
   "source": [
    "print(clf_GT_all_1.score(X_test_1, Test_y_1))\n",
    "print(clf_GT_all_3.score(X_test_3, Test_y_3))\n",
    "print(clf_GT_all_5.score(X_test_5, Test_y_5))\n",
    "print(clf_GT_all_10.score(X_test_10, Test_y_10))\n",
    "print(clf_GT_all_14.score(X_test_14, Test_y_14))\n",
    "print(clf_GT_all_20.score(X_test_20, Test_y_20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whew, this is the end of part 2. For this part, coding is relatively easy compared to the first. However, the tough part is tweaking hyperparameters to get higher validation score. I have to admit that it is difficult to raise validation score significantly beyond this point. Here are some quick notes about what I could observe. I think that could help refine the topic that we could go next, using this as the starting point.\n",
    "\n",
    "- Using dummy classifier, we see the shifting sand in the distribution of (up, sideway, down), and the prediction gets worse as we increase window length.  \n",
    "- Using lagged dependent variable in logistic regression classifier, it is not better than dummy classifier. Unfortunately, the same holds true for the full model using logistic regression framework.  \n",
    "- Using decision tree classifiers (including RF and GBDT), for window lengths of 1 day - 10 days, I do not see any improvements (esp 1-5 days). However, we could see significant improvement (from 30% to 45% accuracy) in window lengths of 14 days & 20 days. The longer, the better the prediction is (seems counterintuitive?) This is confirmed by running the model with test set.  \n",
    "- By inspecting the classification report, for RF, as we increase time span, the model tries to ignore sideway as it became less common. This model is more like a bit risk-seeking because it tries to ignore sideway and bets up or down. However, for GBDT, the degree of aggressiveness is less compared to RF.  \n",
    "- By inspecting the feature importances, I could notice that as we increase the time span, \"trend\", \"momentum\" (esp CCI, MACD) are less important over window length while \"uncertainty\" (STD) is more important over window length. (Importance is measured by feature importances as explanatory power in RF and GBDT)\n",
    "- Looking at similarities among classification report (esp window_length = 14, 20), for (down) the precision is high and recall is low, implying that if the model says stock is going to go down, then it is likely so. However, for (up) the precision is low and recall is high, implying that among opportunities when stock index is going to rise, the model is likely to capture that opportunity. However, by capturing opportunity, it generates more false alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
